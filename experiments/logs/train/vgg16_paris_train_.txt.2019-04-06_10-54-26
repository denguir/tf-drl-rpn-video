+ echo Logging output to experiments/logs/train/vgg16_paris_train_.txt.2019-04-06_10-54-26
Logging output to experiments/logs/train/vgg16_paris_train_.txt.2019-04-06_10-54-26
+ case ${DATASET} in
+ SAVE_PATH=/home/vador/Documents/project/AI/drl-rpn-tf/output-weights/drl-rpn-paris/
+ case ${USE_POST} in
+ WEIGHTS_PATH=/home/vador/Documents/project/AI/drl-rpn-tf/data/pre-trained/drl-rpn-voc2007-2012-trainval/vgg16_drl_rpn_iter_110000.ckpt
+ '[' '!' -f .index ']'
+ [[ ! -z '' ]]
+ CUDA_VISIBLE_DEVICES=0
+ time python ./tools/trainval_net.py --weight /home/vador/Documents/project/AI/drl-rpn-tf/data/pre-trained/drl-rpn-voc2007-2012-trainval/vgg16_drl_rpn_iter_110000.ckpt --save /home/vador/Documents/project/AI/drl-rpn-tf/output-weights/drl-rpn-paris/ --imdb paris_train --imdbval paris_val --iters 1000 --cfg experiments/cfgs/drl-rpn-vgg16.yml --net vgg16 --use_hist 1 --det_start 300 --use_post 0 --set ANCHOR_SCALES '[4,8,16]' ANCHOR_RATIOS '[0.5,1,2]' NBR_CLASSES 21 TRAIN.STEPSIZE '[700]' DRL_RPN_TRAIN.STEPSIZE 800
Called with args:
Namespace(cfg_file='experiments/cfgs/drl-rpn-vgg16.yml', det_start=300, imdb_name='paris_train', imdbval_name='paris_val', max_iters=1000, net='vgg16', save_path='/home/vador/Documents/project/AI/drl-rpn-tf/output-weights/drl-rpn-paris/', set_cfgs=['ANCHOR_SCALES', '[4,8,16]', 'ANCHOR_RATIOS', '[0.5,1,2]', 'NBR_CLASSES', '21', 'TRAIN.STEPSIZE', '[700]', 'DRL_RPN_TRAIN.STEPSIZE', '800'], tag=None, use_hist=1, use_post=0, weight='/home/vador/Documents/project/AI/drl-rpn-tf/data/pre-trained/drl-rpn-voc2007-2012-trainval/vgg16_drl_rpn_iter_110000.ckpt')
Using config:
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [4, 8, 16],
 'CLASS_NAMES': [],
 'COCO_TO_PASCAL': [0,
                    5,
                    2,
                    15,
                    9,
                    40,
                    6,
                    3,
                    16,
                    57,
                    20,
                    61,
                    17,
                    18,
                    4,
                    1,
                    59,
                    19,
                    58,
                    7,
                    63],
 'DATA_DIR': '/home/vador/Documents/project/AI/drl-rpn-tf/data',
 'DIMS_AUX': 39,
 'DIMS_BASE': 512,
 'DIMS_NONHIST': 530,
 'DIMS_TOT': 551,
 'DRL_RPN': {'H_FIXRECT': 0.25,
             'H_HIST': 3,
             'H_SCALE': 0.5,
             'MAX_ITER_TRAJ': 13,
             'MAX_ITER_TRAJ_FLT': 13.0,
             'TOPK_OBJNESS': 0,
             'USE_AGNO': False,
             'USE_HIST': True,
             'USE_POST': False,
             'W_FIXRECT': 0.25,
             'W_HIST': 3,
             'W_SCALE': 0.5},
 'DRL_RPN_TEST': {'BETA': 0.05,
                  'DO_VISUALIZE': False,
                  'NBR_FIX': 0,
                  'RANDOM_DONE': False,
                  'RANDOM_FIX': False},
 'DRL_RPN_TRAIN': {'BATCH_SIZE': 50,
                   'BETAS': [-1, 0.9],
                   'DET_START': -1,
                   'DISPLAY': 50,
                   'GAMMA': 0.2,
                   'IMG_START_IDX': -1,
                   'IOU_THRESH': 0.5,
                   'LEARNING_RATE': 2e-05,
                   'MA_WEIGHT': 0.0005,
                   'POST_BETAS': [0.05, 0.35],
                   'POST_LR': 0.001,
                   'POST_SS': [80000],
                   'STEPSIZE': 800,
                   'USE_BL': True,
                   'USE_FLIPPED': True,
                   'USE_POST': 0},
 'EXP_DIR': 'vgg16_drl_rpn',
 'MATLAB': 'matlab',
 'MEANS_BBOX': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),
 'NBR_ANCHORS': 9,
 'NBR_CLASSES': 21,
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/vador/Documents/project/AI/drl-rpn-tf',
 'RPN_CHANNELS': 512,
 'STDS_BBOX': array([0.1, 0.1, 0.2, 0.2, 0.1, 0.1, 0.2, 0.2, 0.1, 0.1, 0.2, 0.2, 0.1,
       0.1, 0.2, 0.2, 0.1, 0.1, 0.2, 0.2, 0.1, 0.1, 0.2, 0.2, 0.1, 0.1,
       0.2, 0.2, 0.1, 0.1, 0.2, 0.2, 0.1, 0.1, 0.2, 0.2, 0.1, 0.1, 0.2,
       0.2, 0.1, 0.1, 0.2, 0.2, 0.1, 0.1, 0.2, 0.2, 0.1, 0.1, 0.2, 0.2,
       0.1, 0.1, 0.2, 0.2, 0.1, 0.1, 0.2, 0.2, 0.1, 0.1, 0.2, 0.2, 0.1,
       0.1, 0.2, 0.2, 0.1, 0.1, 0.2, 0.2, 0.1, 0.1, 0.2, 0.2, 0.1, 0.1,
       0.2, 0.2, 0.1, 0.1, 0.2, 0.2]),
 'TEST': {'BBOX_REG': True,
          'HAS_RPN': True,
          'MAX_SIZE': 1000,
          'MODE': 'nms',
          'NMS': 0.3,
          'PROPOSAL_METHOD': 'gt',
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000,
          'RPN_TOP_N': 5000,
          'SCALES': [600],
          'SVM': False},
 'TRAIN': {'ASPECT_GROUPING': False,
           'BATCH_SIZE': 128,
           'BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'BBOX_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': True,
           'BBOX_REG': True,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'BIAS_DECAY': False,
           'DISPLAY': 50,
           'DOUBLE_BIAS': False,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'GAMMA': 0.1,
           'HAS_RPN': True,
           'IMS_PER_BATCH': 1,
           'LEARNING_RATE': 0.00025,
           'MAX_SIZE': 1000,
           'MOMENTUM': 0.9,
           'PROPOSAL_METHOD': 'gt',
           'RPN_BATCHSIZE': 128,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000,
           'SCALES': [600],
           'SNAPSHOT_ITERS': 5000,
           'SNAPSHOT_KEPT': 3,
           'SNAPSHOT_PREFIX': 'vgg16_drl_rpn',
           'STEPSIZE': [700],
           'SUMMARY_INTERVAL': 180,
           'TRUNCATED': False,
           'USE_ALL_GT': True,
           'USE_FLIPPED': True,
           'USE_GT': False,
           'WEIGHT_DECAY': 0.0001},
 'USE_GPU_NMS': True,
 'VIS_DIR': '/home/vador/Documents/project/AI/drl-rpn-tf/img-out'}
Loaded dataset `paris_train` for training
Set proposal method: gt
Appending horizontally-flipped training examples...
paris_train gt roidb loaded from /home/vador/Documents/project/AI/drl-rpn-tf/data/cache/paris_train_gt_roidb.pkl
done
Preparing training data...
done
2102 roidb entries
/home/vador/Documents/project/AI/drl-rpn-tf/output-weights/drl-rpn-paris/output/vgg16_drl_rpn/paris_train
Output will be saved to `/home/vador/Documents/project/AI/drl-rpn-tf/output-weights/drl-rpn-paris/output/vgg16_drl_rpn/paris_train`
Loaded dataset `paris_val` for training
Set proposal method: gt
Preparing training data...
paris_val gt roidb loaded from /home/vador/Documents/project/AI/drl-rpn-tf/data/cache/paris_val_gt_roidb.pkl
done
150 validation roidb entries
Filtered 0 roidb entries: 2102 -> 2102
Filtered 0 roidb entries: 150 -> 150
2019-04-06 10:54:47.538300: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-04-06 10:54:47.880364: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1009] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-04-06 10:54:47.929260: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55ecec6d43d0 executing computations on platform CUDA. Devices:
2019-04-06 10:54:47.929283: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce RTX 2070, Compute Capability 7.5
2019-04-06 10:54:48.092777: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3392280000 Hz
2019-04-06 10:54:48.093167: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55ececa00a10 executing computations on platform Host. Devices:
2019-04-06 10:54:48.093203: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-04-06 10:54:48.094116: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1551] Found device 0 with properties: 
name: GeForce RTX 2070 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:01:00.0
totalMemory: 7.76GiB freeMemory: 7.26GiB
2019-04-06 10:54:48.094150: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1674] Adding visible gpu devices: 0
2019-04-06 10:54:48.094239: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-04-06 10:54:48.124782: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1082] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-04-06 10:54:48.124804: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1088]      0 
2019-04-06 10:54:48.124812: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1101] 0:   N 
2019-04-06 10:54:48.125151: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1222] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6360 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2070, pci bus id: 0000:01:00.0, compute capability: 7.5)
Solving...
WARNING: Logging before flag parsing goes to stderr.
W0406 10:54:48.454762 139631622260544 deprecation.py:323] From /home/vador/Documents/project/AI/drl-rpn-tf/tools/../lib/nets/network.py:222: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
W0406 10:54:48.459214 139631622260544 deprecation.py:323] From /home/vador/Documents/project/AI/drl-rpn-tf/tools/../lib/nets/network.py:231: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0406 10:54:48.537502 139631622260544 deprecation.py:323] From /home/vador/Documents/project/AI/drl-rpn-tf/tools/../lib/nets/network.py:128: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
W0406 10:54:48.552891 139631622260544 deprecation.py:506] From /home/vador/Documents/project/AI/drl-rpn-tf/tools/../lib/nets/network.py:141: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.
Instructions for updating:
box_ind is deprecated, use box_indices instead
W0406 10:54:48.556138 139631622260544 deprecation.py:323] From /home/vador/anaconda3/envs/tf10/lib/python3.6/site-packages/tensorflow/contrib/layers/python/layers/layers.py:1624: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.flatten instead.
W0406 10:54:49.157977 139631622260544 deprecation.py:506] From /home/vador/anaconda3/envs/tf10/lib/python3.6/site-packages/tensorflow/python/training/slot_creator.py:187: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
Loading initial model weights from /home/vador/Documents/project/AI/drl-rpn-tf/data/pre-trained/drl-rpn-voc2007-2012-trainval/vgg16_drl_rpn_iter_110000.ckpt
Variables restored: vgg_16/conv1/conv1_1/biases:0
Variables restored: vgg_16/conv1/conv1_2/weights:0
Variables restored: vgg_16/conv1/conv1_2/biases:0
Variables restored: vgg_16/conv2/conv2_1/weights:0
Variables restored: vgg_16/conv2/conv2_1/biases:0
Variables restored: vgg_16/conv2/conv2_2/weights:0
Variables restored: vgg_16/conv2/conv2_2/biases:0
Variables restored: vgg_16/conv3/conv3_1/weights:0
Variables restored: vgg_16/conv3/conv3_1/biases:0
Variables restored: vgg_16/conv3/conv3_2/weights:0
Variables restored: vgg_16/conv3/conv3_2/biases:0
Variables restored: vgg_16/conv3/conv3_3/weights:0
Variables restored: vgg_16/conv3/conv3_3/biases:0
Variables restored: vgg_16/conv4/conv4_1/weights:0
Variables restored: vgg_16/conv4/conv4_1/biases:0
Variables restored: vgg_16/conv4/conv4_2/weights:0
Variables restored: vgg_16/conv4/conv4_2/biases:0
Variables restored: vgg_16/conv4/conv4_3/weights:0
Variables restored: vgg_16/conv4/conv4_3/biases:0
Variables restored: vgg_16/conv5/conv5_1/weights:0
Variables restored: vgg_16/conv5/conv5_1/biases:0
Variables restored: vgg_16/conv5/conv5_2/weights:0
Variables restored: vgg_16/conv5/conv5_2/biases:0
Variables restored: vgg_16/conv5/conv5_3/weights:0
Variables restored: vgg_16/conv5/conv5_3/biases:0
Variables restored: vgg_16/rpn_conv/3x3/weights:0
Variables restored: vgg_16/rpn_conv/3x3/biases:0
Variables restored: vgg_16/rpn_cls_score/weights:0
Variables restored: vgg_16/rpn_cls_score/biases:0
Variables restored: vgg_16/rpn_bbox_pred/weights:0
Variables restored: vgg_16/rpn_bbox_pred/biases:0
Variables restored: vgg_16/fc6/biases:0
Variables restored: vgg_16/fc7/biases:0
Variables restored: vgg_16/cls_score/weights:0
Variables restored: vgg_16/cls_score/biases:0
Variables restored: vgg_16/bbox_pred/weights:0
Variables restored: vgg_16/bbox_pred/biases:0
Variables restored: post_hist/vgg_16/fc6/weights:0
Variables restored: post_hist/vgg_16/fc6/biases:0
Variables restored: post_hist/vgg_16/fc7/weights:0
Variables restored: post_hist/vgg_16/fc7/biases:0
Variables restored: post_hist/hist_tanh_cls/weights:0
Variables restored: post_hist/hist_tanh_cls/biases:0
Variables restored: post_hist/cls_score_hist/weights:0
Variables restored: post_hist/cls_score_hist/biases:0
Variables restored: Variable:0
Variables restored: vgg_16/fc6/weights/Momentum:0
Variables restored: vgg_16/fc6/biases/Momentum:0
Variables restored: vgg_16/fc7/weights/Momentum:0
Variables restored: vgg_16/fc7/biases/Momentum:0
Variables restored: vgg_16/cls_score/weights/Momentum:0
Variables restored: vgg_16/cls_score/biases/Momentum:0
Variables restored: vgg_16/bbox_pred/weights/Momentum:0
Variables restored: vgg_16/bbox_pred/biases/Momentum:0
Variables restored: post_hist/vgg_16/fc6/weights/Momentum:0
Variables restored: post_hist/vgg_16/fc7/weights/Momentum:0
Variables restored: post_hist/hist_tanh_cls/weights/Momentum:0
Variables restored: post_hist/cls_score_hist/weights/Momentum:0
Variables restored: Variable_1:0
Variables restored: post_hist/vgg_16/fc6/weights/Momentum_1:0
Variables restored: post_hist/vgg_16/fc6/biases/Momentum:0
Variables restored: post_hist/vgg_16/fc7/weights/Momentum_1:0
Variables restored: post_hist/vgg_16/fc7/biases/Momentum:0
Variables restored: post_hist/hist_tanh_cls/weights/Momentum_1:0
Variables restored: post_hist/hist_tanh_cls/biases/Momentum:0
Variables restored: post_hist/cls_score_hist/weights/Momentum_1:0
Variables restored: post_hist/cls_score_hist/biases/Momentum:0
Variables restored: xr_weights_base:0
Variables restored: xr_weights_aux:0
Variables restored: xh_weights_base:0
Variables restored: xh_weights_aux:0
Variables restored: xz_weights_base:0
Variables restored: xz_weights_aux:0
Variables restored: hr_weights:0
Variables restored: hh_weights:0
Variables restored: hz_weights:0
Variables restored: h_relu_weights:0
Variables restored: r_bias:0
Variables restored: h_bias:0
Variables restored: z_bias:0
Variables restored: relu_bias:0
Variables restored: additional_weights:0
Variables restored: additional_bias:0
Variables restored: done_weights:0
W0406 10:55:02.018231 139631622260544 deprecation.py:323] From /home/vador/anaconda3/envs/tf10/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
Loaded.
Fix VGG16 layers..
OBS: NOT REVERSING RGB CHANNELS -- set do_reverse=True if reversing is desired!
W0406 10:55:27.972156 139631622260544 deprecation.py:506] From /home/vador/anaconda3/envs/tf10/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
Fixed.
2019-04-06 10:55:37.766911: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-04-06 10:55:43.561995: W tensorflow/core/common_runtime/bfc_allocator.cc:230] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.09GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-04-06 10:55:43.572980: W tensorflow/core/common_runtime/bfc_allocator.cc:230] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.09GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-04-06 10:55:44.662747: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:697] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-04-06 10:55:44.663798: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:697] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-04-06 10:55:44.741566: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0

##### DRL-RPN BATCH GRADIENT UPDATE - START ##### 

iter: 50 / 1000
lr-rl: 0.000020
2019-04-06 10:56:17.646231: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:697] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-04-06 10:56:17.651212: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:697] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
Mean loss (tot, MA):      (-1.548183, -0.000774)
Mean reward (tot, MA):         (-1.661387, -0.040889)
Mean rew-done (tot, MA):       (-5.200000, -0.128308)
Mean traj-len (tot, MA):       (11.120001, 0.274565)
Mean frac-area (tot, MA):      (0.502337, 0.012405)
Mean gt >= 0.5 frac (tot, MA): (0.389711, 0.009625)
Mean gt-IoU-frac (tot, MA):    (0.244743, 0.006045)
Traj-len vs. # gt-instances:
['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '12.00', '11.10']
['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.30', '7.82']
Traj-len vs. betas:
['-1.000: 11.12', '0.900: 0.00']
['-1.000: 7.91', '0.900: 0.00']
TIMINGS:
runnn-drl-rpn: 0.7830
train-drl-rpn: 5.1664

##### DRL-RPN BATCH GRADIENT UPDATE - DONE ###### 


##### DRL-RPN BATCH GRADIENT UPDATE - START ##### 

iter: 100 / 1000
lr-rl: 0.000020
Mean loss (tot, MA):      (1.214370, 0.001215)
Mean reward (tot, MA):         (-7.739370, -0.381011)
Mean rew-done (tot, MA):       (-10.409997, -0.510764)
Mean traj-len (tot, MA):       (7.650002, 0.370963)
Mean frac-area (tot, MA):      (0.363905, 0.017666)
Mean gt >= 0.5 frac (tot, MA): (0.284463, 0.013813)
Mean gt-IoU-frac (tot, MA):    (0.180430, 0.008763)
Traj-len vs. # gt-instances:
['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '7.50', '7.65']
['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.37', '5.19']
Traj-len vs. betas:
['-1.000: 11.12', '0.900: 4.18']
['-1.000: 7.91', '0.900: 2.93']
TIMINGS:
runnn-drl-rpn: 0.5368
train-drl-rpn: 3.7047

##### DRL-RPN BATCH GRADIENT UPDATE - DONE ###### 


##### DRL-RPN BATCH GRADIENT UPDATE - START ##### 

iter: 150 / 1000
lr-rl: 0.000020
Mean loss (tot, MA):      (0.181393, 0.000272)
Mean reward (tot, MA):         (-5.195656, -0.373863)
Mean rew-done (tot, MA):       (-7.996664, -0.576066)
Mean traj-len (tot, MA):       (8.966666, 0.648347)
Mean frac-area (tot, MA):      (0.412975, 0.029855)
Mean gt >= 0.5 frac (tot, MA): (0.298579, 0.021547)
Mean gt-IoU-frac (tot, MA):    (0.188761, 0.013622)
Traj-len vs. # gt-instances:
['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '7.50', '8.99']
['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.37', '9.89']
Traj-len vs. betas:
['-1.000: 11.36', '0.900: 4.18']
['-1.000: 10.65', '0.900: 2.93']
TIMINGS:
runnn-drl-rpn: 0.5611
train-drl-rpn: 3.9651

##### DRL-RPN BATCH GRADIENT UPDATE - DONE ###### 


##### DRL-RPN BATCH GRADIENT UPDATE - START ##### 

iter: 200 / 1000
lr-rl: 0.000020
Mean loss (tot, MA):      (0.937839, 0.001875)
Mean reward (tot, MA):         (-7.195082, -0.690626)
Mean rew-done (tot, MA):       (-9.632497, -0.921120)
Mean traj-len (tot, MA):       (7.444998, 0.703453)
Mean frac-area (tot, MA):      (0.350342, 0.033128)
Mean gt >= 0.5 frac (tot, MA): (0.260649, 0.024643)
Mean gt-IoU-frac (tot, MA):    (0.165476, 0.015647)
Traj-len vs. # gt-instances:
['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '4.80', '7.51']
['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.56', '5.00']
Traj-len vs. betas:
['-1.000: 11.36', '0.900: 3.53']
['-1.000: 10.65', '0.900: 2.89']
TIMINGS:
runnn-drl-rpn: 0.4765
train-drl-rpn: 3.4451

##### DRL-RPN BATCH GRADIENT UPDATE - DONE ###### 


##### DRL-RPN BATCH GRADIENT UPDATE - START ##### 

iter: 250 / 1000
lr-rl: 0.000020
Mean loss (tot, MA):      (0.236475, 0.000590)
Mean reward (tot, MA):         (-5.727201, -0.669995)
Mean rew-done (tot, MA):       (-8.359998, -0.979093)
Mean traj-len (tot, MA):       (8.219998, 0.965595)
Mean frac-area (tot, MA):      (0.379027, 0.044503)
Mean gt >= 0.5 frac (tot, MA): (0.279204, 0.032759)
Mean gt-IoU-frac (tot, MA):    (0.177781, 0.020865)
Traj-len vs. # gt-instances:
['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '4.80', '8.29']
['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.56', '9.48']
Traj-len vs. betas:
['-1.000: 11.35', '0.900: 3.53']
['-1.000: 11.07', '0.900: 2.89']
TIMINGS:
runnn-drl-rpn: 0.5011
train-drl-rpn: 3.6833

##### DRL-RPN BATCH GRADIENT UPDATE - DONE ###### 


##### DRL-RPN BATCH GRADIENT UPDATE - START ##### 

iter: 300 / 1000
lr-rl: 0.000020
Mean loss (tot, MA):      (0.666395, 0.001998)
Mean reward (tot, MA):         (-7.035442, -0.988687)
Mean rew-done (tot, MA):       (-9.405317, -1.316195)
Mean traj-len (tot, MA):       (7.249999, 1.000990)
Mean frac-area (tot, MA):      (0.337983, 0.046682)
Mean gt >= 0.5 frac (tot, MA): (0.254042, 0.035116)
Mean gt-IoU-frac (tot, MA):    (0.161853, 0.022379)
Traj-len vs. # gt-instances:
['0.00', '7.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '4.80', '7.29']
['0.00', '0.17', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.56', '4.34']
Traj-len vs. betas:
['-1.000: 11.35', '0.900: 3.15']
['-1.000: 11.07', '0.900: 2.49']
TIMINGS:
runnn-drl-rpn: 0.4500
train-drl-rpn: 3.3664

##### DRL-RPN BATCH GRADIENT UPDATE - DONE ###### 


##### DRL-RPN BATCH GRADIENT UPDATE - START ##### 

iter: 350 / 1000
lr-rl: 0.000020
Mean loss (tot, MA):      (0.231320, 0.000807)
Mean reward (tot, MA):         (-5.716330, -0.909985)
Mean rew-done (tot, MA):       (-8.274556, -1.320496)
Mean traj-len (tot, MA):       (7.920000, 1.271143)
Mean frac-area (tot, MA):      (0.364370, 0.058436)
Mean gt >= 0.5 frac (tot, MA): (0.274429, 0.044046)
Mean gt-IoU-frac (tot, MA):    (0.174435, 0.027998)
Traj-len vs. # gt-instances:
['0.00', '7.00', '0.00', '0.00', '0.00', '0.00', '0.00', '12.00', '6.00', '7.94']
['0.00', '0.17', '0.00', '0.00', '0.00', '0.00', '0.00', '0.30', '0.85', '9.69']
Traj-len vs. betas:
['-1.000: 11.50', '0.900: 3.15']
['-1.000: 11.70', '0.900: 2.49']
TIMINGS:
runnn-drl-rpn: 0.4795
train-drl-rpn: 3.5355

##### DRL-RPN BATCH GRADIENT UPDATE - DONE ###### 

iter: 350 / 1000, total loss: 0.428304
 >>> loss_cls (detector): 0.202685
 >>> loss_box (detector): 0.143777
 >>> lr: 0.000250
speed: 0.045s / iter

##### DRL-RPN BATCH GRADIENT UPDATE - START ##### 

iter: 400 / 1000
lr-rl: 0.000020
Mean loss (tot, MA):      (0.582431, 0.002327)
Mean reward (tot, MA):         (-6.825682, -1.247887)
Mean rew-done (tot, MA):       (-9.177735, -1.670702)
Mean traj-len (tot, MA):       (7.232500, 1.299512)
Mean frac-area (tot, MA):      (0.334847, 0.060159)
Mean gt >= 0.5 frac (tot, MA): (0.252608, 0.045423)
Mean gt-IoU-frac (tot, MA):    (0.160526, 0.028865)
Traj-len vs. # gt-instances:
['0.00', '7.00', '0.00', '0.00', '0.00', '0.00', '0.00', '12.00', '6.00', '7.24']
['0.00', '0.17', '0.00', '0.00', '0.00', '0.00', '0.00', '0.30', '0.85', '4.47']
Traj-len vs. betas:
['-1.000: 11.50', '0.900: 2.97']
['-1.000: 11.70', '0.900: 2.45']
TIMINGS:
runnn-drl-rpn: 0.4430
train-drl-rpn: 3.3161

##### DRL-RPN BATCH GRADIENT UPDATE - DONE ###### 

iter: 400 / 1000, total loss: 0.652926
 >>> loss_cls (detector): 0.260468
 >>> loss_box (detector): 0.310618
 >>> lr: 0.000250
speed: 0.043s / iter

##### DRL-RPN BATCH GRADIENT UPDATE - START ##### 

iter: 450 / 1000
lr-rl: 0.000020
Mean loss (tot, MA):      (0.340972, 0.001530)
Mean reward (tot, MA):         (-5.804468, -1.158548)
Mean rew-done (tot, MA):       (-8.300211, -1.660976)
Mean traj-len (tot, MA):       (7.751111, 1.561307)
Mean frac-area (tot, MA):      (0.355380, 0.071507)
Mean gt >= 0.5 frac (tot, MA): (0.267200, 0.053791)
Mean gt-IoU-frac (tot, MA):    (0.169588, 0.034136)
Traj-len vs. # gt-instances:
['0.00', '7.00', '0.00', '0.00', '0.00', '0.00', '0.00', '12.00', '6.86', '7.76']
['0.00', '0.17', '0.00', '0.00', '0.00', '0.00', '0.00', '0.30', '1.13', '9.76']
Traj-len vs. betas:
['-1.000: 11.58', '0.900: 2.97']
['-1.000: 11.85', '0.900: 2.45']
TIMINGS:
runnn-drl-rpn: 0.4648
train-drl-rpn: 3.4653

##### DRL-RPN BATCH GRADIENT UPDATE - DONE ###### 

iter: 450 / 1000, total loss: 0.245740
 >>> loss_cls (detector): 0.163902
 >>> loss_box (detector): 0.000000
 >>> lr: 0.000250
speed: 0.041s / iter

##### DRL-RPN BATCH GRADIENT UPDATE - START ##### 

iter: 500 / 1000
lr-rl: 0.000020
Mean loss (tot, MA):      (0.569889, 0.002845)
Mean reward (tot, MA):         (-6.676511, -1.488653)
Mean rew-done (tot, MA):       (-9.028191, -2.004727)
Mean traj-len (tot, MA):       (7.170002, 1.570606)
Mean frac-area (tot, MA):      (0.330973, 0.072487)
Mean gt >= 0.5 frac (tot, MA): (0.251974, 0.055300)
Mean gt-IoU-frac (tot, MA):    (0.159791, 0.035061)
Traj-len vs. # gt-instances:
['0.00', '7.00', '0.00', '0.00', '0.00', '0.00', '0.00', '12.00', '6.86', '7.16']
['0.00', '0.17', '0.00', '0.00', '0.00', '0.00', '0.00', '0.30', '1.13', '4.08']
Traj-len vs. betas:
['-1.000: 11.58', '0.900: 2.76']
['-1.000: 11.85', '0.900: 2.01']
TIMINGS:
runnn-drl-rpn: 0.4354
train-drl-rpn: 3.2743

##### DRL-RPN BATCH GRADIENT UPDATE - DONE ###### 

iter: 500 / 1000, total loss: 0.269929
 >>> loss_cls (detector): 0.094373
 >>> loss_box (detector): 0.093719
 >>> lr: 0.000250
speed: 0.041s / iter

##### DRL-RPN BATCH GRADIENT UPDATE - START ##### 

iter: 550 / 1000
lr-rl: 0.000020
Mean loss (tot, MA):      (0.378619, 0.002076)
Mean reward (tot, MA):         (-5.748415, -1.364657)
Mean rew-done (tot, MA):       (-8.281084, -1.975178)
Mean traj-len (tot, MA):       (7.607275, 1.827681)
Mean frac-area (tot, MA):      (0.349338, 0.083859)
Mean gt >= 0.5 frac (tot, MA): (0.272527, 0.065738)
Mean gt-IoU-frac (tot, MA):    (0.172407, 0.041567)
Traj-len vs. # gt-instances:
['0.00', '7.00', '0.00', '0.00', '0.00', '0.00', '0.00', '12.00', '8.40', '7.59']
['0.00', '0.17', '0.00', '0.00', '0.00', '0.00', '0.00', '0.30', '1.92', '9.58']
Traj-len vs. betas:
['-1.000: 11.64', '0.900: 2.76']
['-1.000: 11.95', '0.900: 2.01']
TIMINGS:
runnn-drl-rpn: 0.4544
train-drl-rpn: 3.3900

##### DRL-RPN BATCH GRADIENT UPDATE - DONE ###### 

iter: 550 / 1000, total loss: 0.502818
 >>> loss_cls (detector): 0.272367
 >>> loss_box (detector): 0.148616
 >>> lr: 0.000250
speed: 0.040s / iter

##### DRL-RPN BATCH GRADIENT UPDATE - START ##### 

iter: 600 / 1000
lr-rl: 0.000020
Mean loss (tot, MA):      (0.571430, 0.003421)
Mean reward (tot, MA):         (-6.505060, -1.697132)
Mean rew-done (tot, MA):       (-8.897661, -2.313611)
Mean traj-len (tot, MA):       (7.133335, 1.829968)
Mean frac-area (tot, MA):      (0.329112, 0.084422)
Mean gt >= 0.5 frac (tot, MA): (0.257344, 0.066345)
Mean gt-IoU-frac (tot, MA):    (0.162609, 0.041894)
Traj-len vs. # gt-instances:
['0.00', '7.00', '0.00', '0.00', '0.00', '0.00', '0.00', '12.00', '8.40', '7.10']
['0.00', '0.17', '0.00', '0.00', '0.00', '0.00', '0.00', '0.30', '1.92', '4.09']
Traj-len vs. betas:
['-1.000: 11.64', '0.900: 2.62']
['-1.000: 11.95', '0.900: 1.96']
TIMINGS:
runnn-drl-rpn: 0.4298
train-drl-rpn: 3.2381

##### DRL-RPN BATCH GRADIENT UPDATE - DONE ###### 

iter: 600 / 1000, total loss: 0.580872
 >>> loss_cls (detector): 0.205230
 >>> loss_box (detector): 0.293809
 >>> lr: 0.000250
speed: 0.040s / iter

##### DRL-RPN BATCH GRADIENT UPDATE - START ##### 

iter: 650 / 1000
lr-rl: 0.000020
Mean loss (tot, MA):      (0.324198, 0.002098)
Mean reward (tot, MA):         (-5.861152, -1.609139)
Mean rew-done (tot, MA):       (-8.329380, -2.293774)
Mean traj-len (tot, MA):       (7.487695, 2.074698)
Mean frac-area (tot, MA):      (0.343228, 0.094995)
Mean gt >= 0.5 frac (tot, MA): (0.265202, 0.073583)
Mean gt-IoU-frac (tot, MA):    (0.167063, 0.046304)
Traj-len vs. # gt-instances:
['0.00', '7.00', '0.00', '0.00', '0.00', '0.00', '0.00', '12.00', '8.40', '7.47']
['0.00', '0.17', '0.00', '0.00', '0.00', '0.00', '0.00', '0.30', '1.92', '9.58']
Traj-len vs. betas:
['-1.000: 11.66', '0.900: 2.62']
['-1.000: 11.80', '0.900: 1.96']
TIMINGS:
runnn-drl-rpn: 0.4445
train-drl-rpn: 3.3400

##### DRL-RPN BATCH GRADIENT UPDATE - DONE ###### 

iter: 650 / 1000, total loss: 0.352609
 >>> loss_cls (detector): 0.193589
 >>> loss_box (detector): 0.077188
 >>> lr: 0.000250
speed: 0.040s / iter

##### DRL-RPN BATCH GRADIENT UPDATE - START ##### 

iter: 700 / 1000
lr-rl: 0.000020
Mean loss (tot, MA):      (0.419442, 0.002926)
Mean reward (tot, MA):         (-6.511985, -1.939262)
Mean rew-done (tot, MA):       (-8.848712, -2.622487)
Mean traj-len (tot, MA):       (7.052860, 2.058036)
Mean frac-area (tot, MA):      (0.324305, 0.094583)
Mean gt >= 0.5 frac (tot, MA): (0.250692, 0.073298)
Mean gt-IoU-frac (tot, MA):    (0.157837, 0.046096)
Traj-len vs. # gt-instances:
['0.00', '7.00', '0.00', '0.00', '0.00', '0.00', '0.00', '12.00', '8.40', '7.03']
['0.00', '0.17', '0.00', '0.00', '0.00', '0.00', '0.00', '0.30', '1.92', '3.71']
Traj-len vs. betas:
['-1.000: 11.66', '0.900: 2.45']
['-1.000: 11.80', '0.900: 1.56']
TIMINGS:
runnn-drl-rpn: 0.4224
train-drl-rpn: 3.2020

##### DRL-RPN BATCH GRADIENT UPDATE - DONE ###### 

iter: 700 / 1000, total loss: 0.858773
 >>> loss_cls (detector): 0.285030
 >>> loss_box (detector): 0.491912
 >>> lr: 0.000025
speed: 0.040s / iter

##### DRL-RPN BATCH GRADIENT UPDATE - START ##### 

iter: 750 / 1000
lr-rl: 0.000020
Mean loss (tot, MA):      (0.233760, 0.001742)
Mean reward (tot, MA):         (-5.891073, -1.822186)
Mean rew-done (tot, MA):       (-8.332134, -2.584929)
Mean traj-len (tot, MA):       (7.368003, 2.298130)
Mean frac-area (tot, MA):      (0.336312, 0.104705)
Mean gt >= 0.5 frac (tot, MA): (0.263302, 0.082350)
Mean gt-IoU-frac (tot, MA):    (0.165489, 0.051692)
Traj-len vs. # gt-instances:
['0.00', '7.00', '0.00', '0.00', '0.00', '0.00', '0.00', '12.00', '8.40', '7.35']
['0.00', '0.17', '0.00', '0.00', '0.00', '0.00', '0.00', '0.30', '1.92', '9.51']
Traj-len vs. betas:
['-1.000: 11.67', '0.900: 2.45']
['-1.000: 11.79', '0.900: 1.56']
TIMINGS:
runnn-drl-rpn: 0.4345
train-drl-rpn: 3.2893

##### DRL-RPN BATCH GRADIENT UPDATE - DONE ###### 

iter: 750 / 1000, total loss: 0.276432
 >>> loss_cls (detector): 0.059090
 >>> loss_box (detector): 0.135513
 >>> lr: 0.000025
speed: 0.040s / iter

##### DRL-RPN BATCH GRADIENT UPDATE - START ##### 

iter: 800 / 1000
lr-rl: 0.000004
Mean loss (tot, MA):      (0.289699, 0.002305)
Mean reward (tot, MA):         (-6.488223, -2.158526)
Mean rew-done (tot, MA):       (-8.806378, -2.914163)
Mean traj-len (tot, MA):       (6.977503, 2.269028)
Mean frac-area (tot, MA):      (0.319132, 0.103635)
Mean gt >= 0.5 frac (tot, MA): (0.250152, 0.081625)
Mean gt-IoU-frac (tot, MA):    (0.157153, 0.051209)
Traj-len vs. # gt-instances:
['0.00', '7.00', '0.00', '0.00', '0.00', '0.00', '0.00', '12.00', '7.73', '6.96']
['0.00', '0.17', '0.00', '0.00', '0.00', '0.00', '0.00', '0.30', '1.90', '3.54']
Traj-len vs. betas:
['-1.000: 11.67', '0.900: 2.28']
['-1.000: 11.79', '0.900: 1.23']
TIMINGS:
runnn-drl-rpn: 0.4145
train-drl-rpn: 3.1683

##### DRL-RPN BATCH GRADIENT UPDATE - DONE ###### 

iter: 800 / 1000, total loss: 0.249046
 >>> loss_cls (detector): 0.081340
 >>> loss_box (detector): 0.085876
 >>> lr: 0.000025
speed: 0.040s / iter

##### DRL-RPN BATCH GRADIENT UPDATE - START ##### 

iter: 850 / 1000
lr-rl: 0.000004
Mean loss (tot, MA):      (0.167198, 0.001408)
Mean reward (tot, MA):         (-5.964529, -2.045491)
Mean rew-done (tot, MA):       (-8.357766, -2.871238)
Mean traj-len (tot, MA):       (7.258826, 2.503449)
Mean frac-area (tot, MA):      (0.330546, 0.113752)
Mean gt >= 0.5 frac (tot, MA): (0.258916, 0.089461)
Mean gt-IoU-frac (tot, MA):    (0.162630, 0.056122)
Traj-len vs. # gt-instances:
['0.00', '7.00', '0.00', '0.00', '0.00', '0.00', '0.00', '12.00', '8.08', '7.24']
['0.00', '0.17', '0.00', '0.00', '0.00', '0.00', '0.00', '0.30', '2.15', '9.42']
Traj-len vs. betas:
['-1.000: 11.68', '0.900: 2.28']
['-1.000: 11.81', '0.900: 1.23']
TIMINGS:
runnn-drl-rpn: 0.4274
train-drl-rpn: 3.2698

##### DRL-RPN BATCH GRADIENT UPDATE - DONE ###### 

iter: 850 / 1000, total loss: 0.152729
 >>> loss_cls (detector): 0.048131
 >>> loss_box (detector): 0.022768
 >>> lr: 0.000025
speed: 0.040s / iter

##### DRL-RPN BATCH GRADIENT UPDATE - START ##### 

iter: 900 / 1000
lr-rl: 0.000004
Mean loss (tot, MA):      (0.207191, 0.001850)
Mean reward (tot, MA):         (-6.490382, -2.376143)
Mean rew-done (tot, MA):       (-8.787888, -3.198061)
Mean traj-len (tot, MA):       (6.920002, 2.470269)
Mean frac-area (tot, MA):      (0.315696, 0.112504)
Mean gt >= 0.5 frac (tot, MA): (0.248298, 0.088927)
Mean gt-IoU-frac (tot, MA):    (0.155853, 0.055740)
Traj-len vs. # gt-instances:
['0.00', '7.00', '0.00', '0.00', '0.00', '0.00', '0.00', '12.00', '8.08', '6.90']
['0.00', '0.17', '0.00', '0.00', '0.00', '0.00', '0.00', '0.30', '2.15', '3.48']
Traj-len vs. betas:
['-1.000: 11.68', '0.900: 2.16']
['-1.000: 11.81', '0.900: 1.17']
TIMINGS:
runnn-drl-rpn: 0.4103
train-drl-rpn: 3.1707

##### DRL-RPN BATCH GRADIENT UPDATE - DONE ###### 

iter: 900 / 1000, total loss: 0.433383
 >>> loss_cls (detector): 0.117316
 >>> loss_box (detector): 0.234237
 >>> lr: 0.000025
speed: 0.040s / iter

##### DRL-RPN BATCH GRADIENT UPDATE - START ##### 

iter: 950 / 1000
lr-rl: 0.000004
Mean loss (tot, MA):      (0.096921, 0.000905)
Mean reward (tot, MA):         (-6.005111, -2.249983)
Mean rew-done (tot, MA):       (-8.387472, -3.148129)
Mean traj-len (tot, MA):       (7.176843, 2.700705)
Mean frac-area (tot, MA):      (0.326345, 0.122519)
Mean gt >= 0.5 frac (tot, MA): (0.257848, 0.097342)
Mean gt-IoU-frac (tot, MA):    (0.161753, 0.060980)
Traj-len vs. # gt-instances:
['0.00', '7.00', '0.00', '0.00', '0.00', '0.00', '0.00', '12.00', '8.38', '7.16']
['0.00', '0.17', '0.00', '0.00', '0.00', '0.00', '0.00', '0.30', '2.40', '9.43']
Traj-len vs. betas:
['-1.000: 11.69', '0.900: 2.16']
['-1.000: 11.85', '0.900: 1.17']
TIMINGS:
runnn-drl-rpn: 0.4235
train-drl-rpn: 3.2551

##### DRL-RPN BATCH GRADIENT UPDATE - DONE ###### 

iter: 950 / 1000, total loss: 0.287874
 >>> loss_cls (detector): 0.134625
 >>> loss_box (detector): 0.071419
 >>> lr: 0.000025
speed: 0.040s / iter

##### DRL-RPN BATCH GRADIENT UPDATE - START ##### 

iter: 1000 / 1000
lr-rl: 0.000004
Mean loss (tot, MA):      (0.103883, 0.001023)
Mean reward (tot, MA):         (-6.482526, -2.578544)
Mean rew-done (tot, MA):       (-8.764096, -3.463564)
Mean traj-len (tot, MA):       (6.868999, 2.659194)
Mean frac-area (tot, MA):      (0.312730, 0.120828)
Mean gt >= 0.5 frac (tot, MA): (0.246817, 0.095857)
Mean gt-IoU-frac (tot, MA):    (0.154885, 0.060076)
Traj-len vs. # gt-instances:
['0.00', '7.00', '0.00', '0.00', '0.00', '0.00', '0.00', '12.00', '8.38', '6.84']
['0.00', '0.17', '0.00', '0.00', '0.00', '0.00', '0.00', '0.30', '2.40', '3.39']
Traj-len vs. betas:
['-1.000: 11.69', '0.900: 2.04']
['-1.000: 11.85', '0.900: 1.06']
TIMINGS:
runnn-drl-rpn: 0.4081
train-drl-rpn: 3.1581

##### DRL-RPN BATCH GRADIENT UPDATE - DONE ###### 

iter: 1000 / 1000, total loss: 0.810224
 >>> loss_cls (detector): 0.192016
 >>> loss_box (detector): 0.536379
 >>> lr: 0.000025
speed: 0.040s / iter
Wrote snapshot to: /home/vador/Documents/project/AI/drl-rpn-tf/output-weights/drl-rpn-paris/output/vgg16_drl_rpn/paris_train/vgg16_drl_rpn_iter_1000.ckpt
done solving
609.26user 156.74system 14:35.15elapsed 87%CPU (0avgtext+0avgdata 9134192maxresident)k
6487968inputs+5799584outputs (4362major+5036018minor)pagefaults 0swaps

+ echo Logging output to experiments/logs/train/vgg16_paris_train_.txt.2019-04-05_20-57-46
Logging output to experiments/logs/train/vgg16_paris_train_.txt.2019-04-05_20-57-46
+ case ${DATASET} in
+ SAVE_PATH=/home/vador/Documents/project/AI/drl-rpn-tf/output-weights/drl-rpn-paris/
+ case ${USE_POST} in
+ WEIGHTS_PATH=/home/vador/Documents/project/AI/drl-rpn-tf/data/pre-trained/drl-rpn-voc2007-2012-trainval/vgg16_drl_rpn_iter_110000.ckpt
+ '[' '!' -f .index ']'
+ [[ ! -z '' ]]
+ CUDA_VISIBLE_DEVICES=0
+ time python ./tools/trainval_net.py --weight /home/vador/Documents/project/AI/drl-rpn-tf/data/pre-trained/drl-rpn-voc2007-2012-trainval/vgg16_drl_rpn_iter_110000.ckpt --save /home/vador/Documents/project/AI/drl-rpn-tf/output-weights/drl-rpn-paris/ --imdb paris_train --imdbval paris_val --iters 1000 --cfg experiments/cfgs/drl-rpn-vgg16.yml --net vgg16 --use_hist 1 --det_start 300 --use_post 0 --set ANCHOR_SCALES '[4,8,16]' ANCHOR_RATIOS '[0.5,1,2]' NBR_CLASSES 21 TRAIN.STEPSIZE '[700]' DRL_RPN_TRAIN.STEPSIZE 800
Called with args:
Namespace(cfg_file='experiments/cfgs/drl-rpn-vgg16.yml', det_start=300, imdb_name='paris_train', imdbval_name='paris_val', max_iters=1000, net='vgg16', save_path='/home/vador/Documents/project/AI/drl-rpn-tf/output-weights/drl-rpn-paris/', set_cfgs=['ANCHOR_SCALES', '[4,8,16]', 'ANCHOR_RATIOS', '[0.5,1,2]', 'NBR_CLASSES', '21', 'TRAIN.STEPSIZE', '[700]', 'DRL_RPN_TRAIN.STEPSIZE', '800'], tag=None, use_hist=1, use_post=0, weight='/home/vador/Documents/project/AI/drl-rpn-tf/data/pre-trained/drl-rpn-voc2007-2012-trainval/vgg16_drl_rpn_iter_110000.ckpt')
Using config:
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [4, 8, 16],
 'CLASS_NAMES': [],
 'COCO_TO_PASCAL': [0,
                    5,
                    2,
                    15,
                    9,
                    40,
                    6,
                    3,
                    16,
                    57,
                    20,
                    61,
                    17,
                    18,
                    4,
                    1,
                    59,
                    19,
                    58,
                    7,
                    63],
 'DATA_DIR': '/home/vador/Documents/project/AI/drl-rpn-tf/data',
 'DIMS_AUX': 39,
 'DIMS_BASE': 512,
 'DIMS_NONHIST': 530,
 'DIMS_TOT': 551,
 'DRL_RPN': {'H_FIXRECT': 0.25,
             'H_HIST': 3,
             'H_SCALE': 0.5,
             'MAX_ITER_TRAJ': 13,
             'MAX_ITER_TRAJ_FLT': 13.0,
             'TOPK_OBJNESS': 0,
             'USE_AGNO': False,
             'USE_HIST': True,
             'USE_POST': False,
             'W_FIXRECT': 0.25,
             'W_HIST': 3,
             'W_SCALE': 0.5},
 'DRL_RPN_TEST': {'BETA': 0.05,
                  'DO_VISUALIZE': False,
                  'NBR_FIX': 0,
                  'RANDOM_DONE': False,
                  'RANDOM_FIX': False},
 'DRL_RPN_TRAIN': {'BATCH_SIZE': 50,
                   'BETAS': [-2, 0.35],
                   'DET_START': -1,
                   'DISPLAY': 50,
                   'GAMMA': 0.2,
                   'IMG_START_IDX': -1,
                   'IOU_THRESH': 0.5,
                   'LEARNING_RATE': 2e-05,
                   'MA_WEIGHT': 0.0005,
                   'POST_BETAS': [0.05, 0.35],
                   'POST_LR': 0.001,
                   'POST_SS': [80000],
                   'STEPSIZE': 800,
                   'USE_BL': True,
                   'USE_FLIPPED': True,
                   'USE_POST': 0},
 'EXP_DIR': 'vgg16_drl_rpn',
 'MATLAB': 'matlab',
 'MEANS_BBOX': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),
 'NBR_ANCHORS': 9,
 'NBR_CLASSES': 21,
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/vador/Documents/project/AI/drl-rpn-tf',
 'RPN_CHANNELS': 512,
 'STDS_BBOX': array([0.1, 0.1, 0.2, 0.2, 0.1, 0.1, 0.2, 0.2, 0.1, 0.1, 0.2, 0.2, 0.1,
       0.1, 0.2, 0.2, 0.1, 0.1, 0.2, 0.2, 0.1, 0.1, 0.2, 0.2, 0.1, 0.1,
       0.2, 0.2, 0.1, 0.1, 0.2, 0.2, 0.1, 0.1, 0.2, 0.2, 0.1, 0.1, 0.2,
       0.2, 0.1, 0.1, 0.2, 0.2, 0.1, 0.1, 0.2, 0.2, 0.1, 0.1, 0.2, 0.2,
       0.1, 0.1, 0.2, 0.2, 0.1, 0.1, 0.2, 0.2, 0.1, 0.1, 0.2, 0.2, 0.1,
       0.1, 0.2, 0.2, 0.1, 0.1, 0.2, 0.2, 0.1, 0.1, 0.2, 0.2, 0.1, 0.1,
       0.2, 0.2, 0.1, 0.1, 0.2, 0.2]),
 'TEST': {'BBOX_REG': True,
          'HAS_RPN': True,
          'MAX_SIZE': 1000,
          'MODE': 'nms',
          'NMS': 0.3,
          'PROPOSAL_METHOD': 'gt',
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000,
          'RPN_TOP_N': 5000,
          'SCALES': [600],
          'SVM': False},
 'TRAIN': {'ASPECT_GROUPING': False,
           'BATCH_SIZE': 128,
           'BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'BBOX_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': True,
           'BBOX_REG': True,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'BIAS_DECAY': False,
           'DISPLAY': 50,
           'DOUBLE_BIAS': False,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'GAMMA': 0.1,
           'HAS_RPN': True,
           'IMS_PER_BATCH': 1,
           'LEARNING_RATE': 0.00025,
           'MAX_SIZE': 1000,
           'MOMENTUM': 0.9,
           'PROPOSAL_METHOD': 'gt',
           'RPN_BATCHSIZE': 128,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000,
           'SCALES': [600],
           'SNAPSHOT_ITERS': 5000,
           'SNAPSHOT_KEPT': 3,
           'SNAPSHOT_PREFIX': 'vgg16_drl_rpn',
           'STEPSIZE': [700],
           'SUMMARY_INTERVAL': 180,
           'TRUNCATED': False,
           'USE_ALL_GT': True,
           'USE_FLIPPED': True,
           'USE_GT': False,
           'WEIGHT_DECAY': 0.0001},
 'USE_GPU_NMS': True,
 'VIS_DIR': '/home/vador/Documents/project/AI/drl-rpn-tf/img-out'}
Loaded dataset `paris_train` for training
Set proposal method: gt
Appending horizontally-flipped training examples...
paris_train gt roidb loaded from /home/vador/Documents/project/AI/drl-rpn-tf/data/cache/paris_train_gt_roidb.pkl
done
Preparing training data...
done
2102 roidb entries
/home/vador/Documents/project/AI/drl-rpn-tf/output-weights/drl-rpn-paris/output/vgg16_drl_rpn/paris_train
Output will be saved to `/home/vador/Documents/project/AI/drl-rpn-tf/output-weights/drl-rpn-paris/output/vgg16_drl_rpn/paris_train`
Loaded dataset `paris_val` for training
Set proposal method: gt
Preparing training data...
paris_val gt roidb loaded from /home/vador/Documents/project/AI/drl-rpn-tf/data/cache/paris_val_gt_roidb.pkl
done
150 validation roidb entries
Filtered 0 roidb entries: 2102 -> 2102
Filtered 0 roidb entries: 150 -> 150
2019-04-05 20:57:50.060105: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-04-05 20:57:50.166544: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1009] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-04-05 20:57:50.167665: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5617129ee3d0 executing computations on platform CUDA. Devices:
2019-04-05 20:57:50.167692: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce RTX 2070, Compute Capability 7.5
2019-04-05 20:57:50.188996: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3392290000 Hz
2019-04-05 20:57:50.189331: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x561712d1aa10 executing computations on platform Host. Devices:
2019-04-05 20:57:50.189354: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-04-05 20:57:50.189859: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1551] Found device 0 with properties: 
name: GeForce RTX 2070 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:01:00.0
totalMemory: 7.76GiB freeMemory: 7.19GiB
2019-04-05 20:57:50.189878: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1674] Adding visible gpu devices: 0
2019-04-05 20:57:50.189942: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-04-05 20:57:50.191115: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1082] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-04-05 20:57:50.191132: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1088]      0 
2019-04-05 20:57:50.191139: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1101] 0:   N 
2019-04-05 20:57:50.191561: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1222] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6360 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2070, pci bus id: 0000:01:00.0, compute capability: 7.5)
Solving...
WARNING: Logging before flag parsing goes to stderr.
W0405 20:57:50.414091 140477873137472 deprecation.py:323] From /home/vador/Documents/project/AI/drl-rpn-tf/tools/../lib/nets/network.py:222: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
W0405 20:57:50.418701 140477873137472 deprecation.py:323] From /home/vador/Documents/project/AI/drl-rpn-tf/tools/../lib/nets/network.py:231: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0405 20:57:50.498014 140477873137472 deprecation.py:323] From /home/vador/Documents/project/AI/drl-rpn-tf/tools/../lib/nets/network.py:128: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
W0405 20:57:50.513799 140477873137472 deprecation.py:506] From /home/vador/Documents/project/AI/drl-rpn-tf/tools/../lib/nets/network.py:141: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.
Instructions for updating:
box_ind is deprecated, use box_indices instead
W0405 20:57:50.516804 140477873137472 deprecation.py:323] From /home/vador/anaconda3/envs/tf10/lib/python3.6/site-packages/tensorflow/contrib/layers/python/layers/layers.py:1624: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.flatten instead.
W0405 20:57:50.948083 140477873137472 deprecation.py:506] From /home/vador/anaconda3/envs/tf10/lib/python3.6/site-packages/tensorflow/python/training/slot_creator.py:187: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
Loading initial model weights from /home/vador/Documents/project/AI/drl-rpn-tf/data/pre-trained/drl-rpn-voc2007-2012-trainval/vgg16_drl_rpn_iter_110000.ckpt
Variables restored: vgg_16/conv1/conv1_1/biases:0
Variables restored: vgg_16/conv1/conv1_2/weights:0
Variables restored: vgg_16/conv1/conv1_2/biases:0
Variables restored: vgg_16/conv2/conv2_1/weights:0
Variables restored: vgg_16/conv2/conv2_1/biases:0
Variables restored: vgg_16/conv2/conv2_2/weights:0
Variables restored: vgg_16/conv2/conv2_2/biases:0
Variables restored: vgg_16/conv3/conv3_1/weights:0
Variables restored: vgg_16/conv3/conv3_1/biases:0
Variables restored: vgg_16/conv3/conv3_2/weights:0
Variables restored: vgg_16/conv3/conv3_2/biases:0
Variables restored: vgg_16/conv3/conv3_3/weights:0
Variables restored: vgg_16/conv3/conv3_3/biases:0
Variables restored: vgg_16/conv4/conv4_1/weights:0
Variables restored: vgg_16/conv4/conv4_1/biases:0
Variables restored: vgg_16/conv4/conv4_2/weights:0
Variables restored: vgg_16/conv4/conv4_2/biases:0
Variables restored: vgg_16/conv4/conv4_3/weights:0
Variables restored: vgg_16/conv4/conv4_3/biases:0
Variables restored: vgg_16/conv5/conv5_1/weights:0
Variables restored: vgg_16/conv5/conv5_1/biases:0
Variables restored: vgg_16/conv5/conv5_2/weights:0
Variables restored: vgg_16/conv5/conv5_2/biases:0
Variables restored: vgg_16/conv5/conv5_3/weights:0
Variables restored: vgg_16/conv5/conv5_3/biases:0
Variables restored: vgg_16/rpn_conv/3x3/weights:0
Variables restored: vgg_16/rpn_conv/3x3/biases:0
Variables restored: vgg_16/rpn_cls_score/weights:0
Variables restored: vgg_16/rpn_cls_score/biases:0
Variables restored: vgg_16/rpn_bbox_pred/weights:0
Variables restored: vgg_16/rpn_bbox_pred/biases:0
Variables restored: vgg_16/fc6/biases:0
Variables restored: vgg_16/fc7/biases:0
Variables restored: vgg_16/cls_score/weights:0
Variables restored: vgg_16/cls_score/biases:0
Variables restored: vgg_16/bbox_pred/weights:0
Variables restored: vgg_16/bbox_pred/biases:0
Variables restored: post_hist/vgg_16/fc6/weights:0
Variables restored: post_hist/vgg_16/fc6/biases:0
Variables restored: post_hist/vgg_16/fc7/weights:0
Variables restored: post_hist/vgg_16/fc7/biases:0
Variables restored: post_hist/hist_tanh_cls/weights:0
Variables restored: post_hist/hist_tanh_cls/biases:0
Variables restored: post_hist/cls_score_hist/weights:0
Variables restored: post_hist/cls_score_hist/biases:0
Variables restored: Variable:0
Variables restored: vgg_16/fc6/weights/Momentum:0
Variables restored: vgg_16/fc6/biases/Momentum:0
Variables restored: vgg_16/fc7/weights/Momentum:0
Variables restored: vgg_16/fc7/biases/Momentum:0
Variables restored: vgg_16/cls_score/weights/Momentum:0
Variables restored: vgg_16/cls_score/biases/Momentum:0
Variables restored: vgg_16/bbox_pred/weights/Momentum:0
Variables restored: vgg_16/bbox_pred/biases/Momentum:0
Variables restored: post_hist/vgg_16/fc6/weights/Momentum:0
Variables restored: post_hist/vgg_16/fc7/weights/Momentum:0
Variables restored: post_hist/hist_tanh_cls/weights/Momentum:0
Variables restored: post_hist/cls_score_hist/weights/Momentum:0
Variables restored: Variable_1:0
Variables restored: post_hist/vgg_16/fc6/weights/Momentum_1:0
Variables restored: post_hist/vgg_16/fc6/biases/Momentum:0
Variables restored: post_hist/vgg_16/fc7/weights/Momentum_1:0
Variables restored: post_hist/vgg_16/fc7/biases/Momentum:0
Variables restored: post_hist/hist_tanh_cls/weights/Momentum_1:0
Variables restored: post_hist/hist_tanh_cls/biases/Momentum:0
Variables restored: post_hist/cls_score_hist/weights/Momentum_1:0
Variables restored: post_hist/cls_score_hist/biases/Momentum:0
Variables restored: xr_weights_base:0
Variables restored: xr_weights_aux:0
Variables restored: xh_weights_base:0
Variables restored: xh_weights_aux:0
Variables restored: xz_weights_base:0
Variables restored: xz_weights_aux:0
Variables restored: hr_weights:0
Variables restored: hh_weights:0
Variables restored: hz_weights:0
Variables restored: h_relu_weights:0
Variables restored: r_bias:0
Variables restored: h_bias:0
Variables restored: z_bias:0
Variables restored: relu_bias:0
Variables restored: additional_weights:0
Variables restored: additional_bias:0
Variables restored: done_weights:0
W0405 20:57:55.840054 140477873137472 deprecation.py:323] From /home/vador/anaconda3/envs/tf10/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
Loaded.
Fix VGG16 layers..
OBS: NOT REVERSING RGB CHANNELS -- set do_reverse=True if reversing is desired!
W0405 20:58:20.517770 140477873137472 deprecation.py:506] From /home/vador/anaconda3/envs/tf10/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
Fixed.
2019-04-05 20:58:29.637921: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-04-05 20:58:35.298531: W tensorflow/core/common_runtime/bfc_allocator.cc:230] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.09GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-04-05 20:58:35.298581: W tensorflow/core/common_runtime/bfc_allocator.cc:230] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.09GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-04-05 20:58:36.247061: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:697] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-04-05 20:58:36.248101: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:697] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-04-05 20:58:36.293784: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0

##### DRL-RPN BATCH GRADIENT UPDATE - START ##### 

iter: 50 / 1000
lr-rl: 0.000020
2019-04-05 20:59:09.335941: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:697] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-04-05 20:59:09.341064: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:697] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
Mean loss (tot, MA):      (-0.802426, -0.000401)
Mean reward (tot, MA):         (2.140431, 0.053044)
Mean rew-done (tot, MA):       (-1.100000, -0.027041)
Mean traj-len (tot, MA):       (11.720001, 0.289506)
Mean frac-area (tot, MA):      (0.516021, 0.012748)
Mean gt >= 0.5 frac (tot, MA): (0.362152, 0.008947)
Mean gt-IoU-frac (tot, MA):    (0.224636, 0.005550)
Traj-len vs. # gt-instances:
['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '12.00', '11.71']
['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.30', '8.41']
Traj-len vs. betas:
['-2.000: 11.72', '0.350: 0.00']
['-2.000: 8.50', '0.350: 0.00']
TIMINGS:
runnn-drl-rpn: 0.7751
train-drl-rpn: 5.2276

##### DRL-RPN BATCH GRADIENT UPDATE - DONE ###### 


##### DRL-RPN BATCH GRADIENT UPDATE - START ##### 

iter: 100 / 1000
lr-rl: 0.000020
Mean loss (tot, MA):      (1.576120, 0.001576)
Mean reward (tot, MA):         (-5.970209, -0.295909)
Mean rew-done (tot, MA):       (-8.360000, -0.411999)
Mean traj-len (tot, MA):       (7.520001, 0.364356)
Mean frac-area (tot, MA):      (0.348737, 0.016915)
Mean gt >= 0.5 frac (tot, MA): (0.258049, 0.012528)
Mean gt-IoU-frac (tot, MA):    (0.161876, 0.007860)
Traj-len vs. # gt-instances:
['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '7.50', '7.52']
['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.37', '4.82']
Traj-len vs. betas:
['-2.000: 11.72', '0.350: 3.32']
['-2.000: 8.50', '0.350: 2.40']
TIMINGS:
runnn-drl-rpn: 0.5085
train-drl-rpn: 3.5987

##### DRL-RPN BATCH GRADIENT UPDATE - DONE ###### 


##### DRL-RPN BATCH GRADIENT UPDATE - START ##### 

iter: 150 / 1000
lr-rl: 0.000020
Mean loss (tot, MA):      (0.535510, 0.000803)
Mean reward (tot, MA):         (-3.851494, -0.279147)
Mean rew-done (tot, MA):       (-6.229998, -0.450540)
Mean traj-len (tot, MA):       (8.900004, 0.643314)
Mean frac-area (tot, MA):      (0.393172, 0.028404)
Mean gt >= 0.5 frac (tot, MA): (0.258137, 0.018596)
Mean gt-IoU-frac (tot, MA):    (0.161627, 0.011644)
Traj-len vs. # gt-instances:
['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '7.50', '8.92']
['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.37', '9.73']
Traj-len vs. betas:
['-2.000: 11.69', '0.350: 3.32']
['-2.000: 10.77', '0.350: 2.40']
TIMINGS:
runnn-drl-rpn: 0.5306
train-drl-rpn: 3.9865

##### DRL-RPN BATCH GRADIENT UPDATE - DONE ###### 


##### DRL-RPN BATCH GRADIENT UPDATE - START ##### 

iter: 200 / 1000
lr-rl: 0.000020
Mean loss (tot, MA):      (0.906993, 0.001813)
Mean reward (tot, MA):         (-6.288073, -0.608181)
Mean rew-done (tot, MA):       (-8.307499, -0.798694)
Mean traj-len (tot, MA):       (7.220003, 0.681293)
Mean frac-area (tot, MA):      (0.326016, 0.030779)
Mean gt >= 0.5 frac (tot, MA): (0.218019, 0.020556)
Mean gt-IoU-frac (tot, MA):    (0.136747, 0.012895)
Traj-len vs. # gt-instances:
['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '4.40', '7.29']
['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.51', '4.52']
Traj-len vs. betas:
['-2.000: 11.69', '0.350: 2.75']
['-2.000: 10.77', '0.350: 2.29']
TIMINGS:
runnn-drl-rpn: 0.4437
train-drl-rpn: 3.4054

##### DRL-RPN BATCH GRADIENT UPDATE - DONE ###### 


##### DRL-RPN BATCH GRADIENT UPDATE - START ##### 

iter: 250 / 1000
lr-rl: 0.000020
Mean loss (tot, MA):      (0.304349, 0.000759)
Mean reward (tot, MA):         (-4.963585, -0.584883)
Mean rew-done (tot, MA):       (-7.179999, -0.844847)
Mean traj-len (tot, MA):       (8.024001, 0.942023)
Mean frac-area (tot, MA):      (0.356307, 0.041811)
Mean gt >= 0.5 frac (tot, MA): (0.238339, 0.027937)
Mean gt-IoU-frac (tot, MA):    (0.149772, 0.017559)
Traj-len vs. # gt-instances:
['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '4.40', '8.10']
['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.51', '9.32']
Traj-len vs. betas:
['-2.000: 11.54', '0.350: 2.75']
['-2.000: 11.08', '0.350: 2.29']
TIMINGS:
runnn-drl-rpn: 0.4696
train-drl-rpn: 3.5977

##### DRL-RPN BATCH GRADIENT UPDATE - DONE ###### 


##### DRL-RPN BATCH GRADIENT UPDATE - START ##### 

iter: 300 / 1000
lr-rl: 0.000020
Mean loss (tot, MA):      (0.536858, 0.001608)
Mean reward (tot, MA):         (-6.481796, -0.917935)
Mean rew-done (tot, MA):       (-8.426665, -1.185957)
Mean traj-len (tot, MA):       (6.966668, 0.960259)
Mean frac-area (tot, MA):      (0.312305, 0.043057)
Mean gt >= 0.5 frac (tot, MA): (0.209648, 0.028880)
Mean gt-IoU-frac (tot, MA):    (0.131690, 0.018144)
Traj-len vs. # gt-instances:
['0.00', '2.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '4.40', '7.03']
['0.00', '0.05', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.51', '3.90']
Traj-len vs. betas:
['-2.000: 11.54', '0.350: 2.39']
['-2.000: 11.08', '0.350: 1.86']
TIMINGS:
runnn-drl-rpn: 0.4159
train-drl-rpn: 3.2451

##### DRL-RPN BATCH GRADIENT UPDATE - DONE ###### 


##### DRL-RPN BATCH GRADIENT UPDATE - START ##### 

iter: 350 / 1000
lr-rl: 0.000020
Mean loss (tot, MA):      (0.279407, 0.000975)
Mean reward (tot, MA):         (-5.277153, -0.847105)
Mean rew-done (tot, MA):       (-7.427142, -1.192038)
Mean traj-len (tot, MA):       (7.619999, 1.221547)
Mean frac-area (tot, MA):      (0.335904, 0.053788)
Mean gt >= 0.5 frac (tot, MA): (0.232536, 0.037304)
Mean gt-IoU-frac (tot, MA):    (0.146049, 0.023431)
Traj-len vs. # gt-instances:
['0.00', '2.00', '0.00', '0.00', '0.00', '0.00', '0.00', '12.00', '5.67', '7.66']
['0.00', '0.05', '0.00', '0.00', '0.00', '0.00', '0.00', '0.30', '0.80', '9.28']
Traj-len vs. betas:
['-2.000: 11.54', '0.350: 2.39']
['-2.000: 11.43', '0.350: 1.86']
TIMINGS:
runnn-drl-rpn: 0.4433
train-drl-rpn: 3.4251

##### DRL-RPN BATCH GRADIENT UPDATE - DONE ###### 

iter: 350 / 1000, total loss: 0.492674
 >>> loss_cls (detector): 0.315749
 >>> loss_box (detector): 0.095082
 >>> lr: 0.000250
speed: 0.043s / iter

##### DRL-RPN BATCH GRADIENT UPDATE - START ##### 

iter: 400 / 1000
lr-rl: 0.000020
Mean loss (tot, MA):      (0.400540, 0.001599)
Mean reward (tot, MA):         (-6.466098, -1.191461)
Mean rew-done (tot, MA):       (-8.436251, -1.545416)
Mean traj-len (tot, MA):       (6.842499, 1.225935)
Mean frac-area (tot, MA):      (0.303450, 0.054343)
Mean gt >= 0.5 frac (tot, MA): (0.213487, 0.038359)
Mean gt-IoU-frac (tot, MA):    (0.134097, 0.024096)
Traj-len vs. # gt-instances:
['0.00', '2.00', '0.00', '0.00', '0.00', '0.00', '0.00', '12.00', '5.67', '6.86']
['0.00', '0.05', '0.00', '0.00', '0.00', '0.00', '0.00', '0.30', '0.80', '3.60']
Traj-len vs. betas:
['-2.000: 11.54', '0.350: 2.15']
['-2.000: 11.43', '0.350: 1.51']
TIMINGS:
runnn-drl-rpn: 0.4045
train-drl-rpn: 3.1795

##### DRL-RPN BATCH GRADIENT UPDATE - DONE ###### 

iter: 400 / 1000, total loss: 0.479943
 >>> loss_cls (detector): 0.191042
 >>> loss_box (detector): 0.207060
 >>> lr: 0.000250
speed: 0.041s / iter

##### DRL-RPN BATCH GRADIENT UPDATE - START ##### 

iter: 450 / 1000
lr-rl: 0.000020
Mean loss (tot, MA):      (0.127421, 0.000569)
Mean reward (tot, MA):         (-5.501911, -1.107550)
Mean rew-done (tot, MA):       (-7.644444, -1.539669)
Mean traj-len (tot, MA):       (7.395557, 1.487544)
Mean frac-area (tot, MA):      (0.324529, 0.065178)
Mean gt >= 0.5 frac (tot, MA): (0.230789, 0.046526)
Mean gt-IoU-frac (tot, MA):    (0.144814, 0.029193)
Traj-len vs. # gt-instances:
['0.00', '2.00', '0.00', '0.00', '0.00', '0.00', '0.00', '12.00', '6.57', '7.41']
['0.00', '0.05', '0.00', '0.00', '0.00', '0.00', '0.00', '0.30', '1.08', '9.40']
Traj-len vs. betas:
['-2.000: 11.60', '0.350: 2.15']
['-2.000: 11.68', '0.350: 1.51']
TIMINGS:
runnn-drl-rpn: 0.4270
train-drl-rpn: 3.3432

##### DRL-RPN BATCH GRADIENT UPDATE - DONE ###### 

iter: 450 / 1000, total loss: 0.217427
 >>> loss_cls (detector): 0.135588
 >>> loss_box (detector): 0.000000
 >>> lr: 0.000250
speed: 0.040s / iter

##### DRL-RPN BATCH GRADIENT UPDATE - START ##### 

iter: 500 / 1000
lr-rl: 0.000020
Mean loss (tot, MA):      (0.324457, 0.001618)
Mean reward (tot, MA):         (-6.446453, -1.449337)
Mean rew-done (tot, MA):       (-8.437999, -1.886417)
Mean traj-len (tot, MA):       (6.778001, 1.480947)
Mean frac-area (tot, MA):      (0.298939, 0.065264)
Mean gt >= 0.5 frac (tot, MA): (0.214742, 0.047113)
Mean gt-IoU-frac (tot, MA):    (0.134724, 0.029556)
Traj-len vs. # gt-instances:
['0.00', '2.00', '0.00', '0.00', '0.00', '0.00', '0.00', '12.00', '6.57', '6.78']
['0.00', '0.05', '0.00', '0.00', '0.00', '0.00', '0.00', '0.30', '1.08', '3.54']
Traj-len vs. betas:
['-2.000: 11.60', '0.350: 1.96']
['-2.000: 11.68', '0.350: 1.31']
TIMINGS:
runnn-drl-rpn: 0.3965
train-drl-rpn: 3.1436

##### DRL-RPN BATCH GRADIENT UPDATE - DONE ###### 

iter: 500 / 1000, total loss: 0.237243
 >>> loss_cls (detector): 0.077036
 >>> loss_box (detector): 0.078370
 >>> lr: 0.000250
speed: 0.040s / iter

##### DRL-RPN BATCH GRADIENT UPDATE - START ##### 

iter: 550 / 1000
lr-rl: 0.000020
Mean loss (tot, MA):      (0.124792, 0.000681)
Mean reward (tot, MA):         (-5.676262, -1.363478)
Mean rew-done (tot, MA):       (-7.809091, -1.877259)
Mean traj-len (tot, MA):       (7.203638, 1.727442)
Mean frac-area (tot, MA):      (0.315150, 0.075440)
Mean gt >= 0.5 frac (tot, MA): (0.230776, 0.055603)
Mean gt-IoU-frac (tot, MA):    (0.144517, 0.034810)
Traj-len vs. # gt-instances:
['0.00', '2.00', '0.00', '0.00', '0.00', '0.00', '0.00', '12.00', '8.10', '7.19']
['0.00', '0.05', '0.00', '0.00', '0.00', '0.00', '0.00', '0.30', '1.85', '9.12']
Traj-len vs. betas:
['-2.000: 11.57', '0.350: 1.96']
['-2.000: 11.61', '0.350: 1.31']
TIMINGS:
runnn-drl-rpn: 0.4135
train-drl-rpn: 3.2665

##### DRL-RPN BATCH GRADIENT UPDATE - DONE ###### 

iter: 550 / 1000, total loss: 0.385368
 >>> loss_cls (detector): 0.274538
 >>> loss_box (detector): 0.028993
 >>> lr: 0.000250
speed: 0.040s / iter

##### DRL-RPN BATCH GRADIENT UPDATE - START ##### 

iter: 600 / 1000
lr-rl: 0.000020
Mean loss (tot, MA):      (0.176257, 0.001052)
Mean reward (tot, MA):         (-6.472705, -1.705978)
Mean rew-done (tot, MA):       (-8.465000, -2.218110)
Mean traj-len (tot, MA):       (6.691667, 1.710964)
Mean frac-area (tot, MA):      (0.293709, 0.075006)
Mean gt >= 0.5 frac (tot, MA): (0.215637, 0.055445)
Mean gt-IoU-frac (tot, MA):    (0.135005, 0.034701)
Traj-len vs. # gt-instances:
['0.00', '2.00', '0.00', '0.00', '0.00', '0.00', '0.00', '12.00', '8.10', '6.67']
['0.00', '0.05', '0.00', '0.00', '0.00', '0.00', '0.00', '0.30', '1.85', '3.34']
Traj-len vs. betas:
['-2.000: 11.57', '0.350: 1.81']
['-2.000: 11.61', '0.350: 1.14']
TIMINGS:
runnn-drl-rpn: 0.3882
train-drl-rpn: 3.1054

##### DRL-RPN BATCH GRADIENT UPDATE - DONE ###### 

iter: 600 / 1000, total loss: 0.552668
 >>> loss_cls (detector): 0.240593
 >>> loss_box (detector): 0.230241
 >>> lr: 0.000250
speed: 0.039s / iter

##### DRL-RPN BATCH GRADIENT UPDATE - START ##### 

iter: 650 / 1000
lr-rl: 0.000020
Mean loss (tot, MA):      (0.061008, 0.000390)
Mean reward (tot, MA):         (-5.873114, -1.631117)
Mean rew-done (tot, MA):       (-7.947690, -2.206278)
Mean traj-len (tot, MA):       (7.066154, 1.954194)
Mean frac-area (tot, MA):      (0.307577, 0.084860)
Mean gt >= 0.5 frac (tot, MA): (0.223405, 0.061899)
Mean gt-IoU-frac (tot, MA):    (0.139896, 0.038752)
Traj-len vs. # gt-instances:
['0.00', '2.00', '0.00', '0.00', '0.00', '0.00', '0.00', '12.00', '8.10', '7.05']
['0.00', '0.05', '0.00', '0.00', '0.00', '0.00', '0.00', '0.30', '1.85', '9.25']
Traj-len vs. betas:
['-2.000: 11.57', '0.350: 1.81']
['-2.000: 11.58', '0.350: 1.14']
TIMINGS:
runnn-drl-rpn: 0.4043
train-drl-rpn: 3.2181

##### DRL-RPN BATCH GRADIENT UPDATE - DONE ###### 

iter: 650 / 1000, total loss: 0.330072
 >>> loss_cls (detector): 0.169210
 >>> loss_box (detector): 0.079029
 >>> lr: 0.000250
speed: 0.040s / iter

##### DRL-RPN BATCH GRADIENT UPDATE - START ##### 

iter: 700 / 1000
lr-rl: 0.000020
Mean loss (tot, MA):      (0.100376, 0.000696)
Mean reward (tot, MA):         (-6.535277, -1.964938)
Mean rew-done (tot, MA):       (-8.494285, -2.537151)
Mean traj-len (tot, MA):       (6.634285, 1.931134)
Mean frac-area (tot, MA):      (0.289681, 0.084173)
Mean gt >= 0.5 frac (tot, MA): (0.210611, 0.061462)
Mean gt-IoU-frac (tot, MA):    (0.131915, 0.038489)
Traj-len vs. # gt-instances:
['0.00', '2.00', '0.00', '0.00', '0.00', '0.00', '0.00', '12.00', '8.10', '6.61']
['0.00', '0.05', '0.00', '0.00', '0.00', '0.00', '0.00', '0.30', '1.85', '3.36']
Traj-len vs. betas:
['-2.000: 11.57', '0.350: 1.70']
['-2.000: 11.58', '0.350: 1.07']
TIMINGS:
runnn-drl-rpn: 0.3837
train-drl-rpn: 3.0828

##### DRL-RPN BATCH GRADIENT UPDATE - DONE ###### 

iter: 700 / 1000, total loss: 0.881372
 >>> loss_cls (detector): 0.302985
 >>> loss_box (detector): 0.496556
 >>> lr: 0.000025
speed: 0.040s / iter

##### DRL-RPN BATCH GRADIENT UPDATE - START ##### 

iter: 750 / 1000
lr-rl: 0.000020
Mean loss (tot, MA):      (0.024544, 0.000177)
Mean reward (tot, MA):         (-5.961958, -1.865352)
Mean rew-done (tot, MA):       (-8.001996, -2.501894)
Mean traj-len (tot, MA):       (6.957333, 2.166963)
Mean frac-area (tot, MA):      (0.301891, 0.093772)
Mean gt >= 0.5 frac (tot, MA): (0.220654, 0.068869)
Mean gt-IoU-frac (tot, MA):    (0.137957, 0.043036)
Traj-len vs. # gt-instances:
['0.00', '2.00', '0.00', '0.00', '0.00', '0.00', '0.00', '12.00', '8.10', '6.94']
['0.00', '0.05', '0.00', '0.00', '0.00', '0.00', '0.00', '0.30', '1.85', '9.22']
Traj-len vs. betas:
['-2.000: 11.56', '0.350: 1.70']
['-2.000: 11.54', '0.350: 1.07']
TIMINGS:
runnn-drl-rpn: 0.3965
train-drl-rpn: 3.1768

##### DRL-RPN BATCH GRADIENT UPDATE - DONE ###### 

iter: 750 / 1000, total loss: 0.082100
 >>> loss_cls (detector): 0.000269
 >>> loss_box (detector): 0.000000
 >>> lr: 0.000025
speed: 0.040s / iter

##### DRL-RPN BATCH GRADIENT UPDATE - START ##### 

iter: 800 / 1000
lr-rl: 0.000004
Mean loss (tot, MA):      (0.033381, 0.000260)
Mean reward (tot, MA):         (-6.555447, -2.200954)
Mean rew-done (tot, MA):       (-8.496872, -2.833180)
Mean traj-len (tot, MA):       (6.584999, 2.138134)
Mean frac-area (tot, MA):      (0.286411, 0.092794)
Mean gt >= 0.5 frac (tot, MA): (0.209656, 0.068271)
Mean gt-IoU-frac (tot, MA):    (0.131072, 0.042659)
Traj-len vs. # gt-instances:
['0.00', '2.00', '0.00', '0.00', '0.00', '0.00', '0.00', '12.00', '7.45', '6.57']
['0.00', '0.05', '0.00', '0.00', '0.00', '0.00', '0.00', '0.30', '1.83', '3.36']
Traj-len vs. betas:
['-2.000: 11.56', '0.350: 1.61']
['-2.000: 11.54', '0.350: 1.00']
TIMINGS:
runnn-drl-rpn: 0.3788
train-drl-rpn: 3.0597

##### DRL-RPN BATCH GRADIENT UPDATE - DONE ###### 

iter: 800 / 1000, total loss: 0.090063
 >>> loss_cls (detector): 0.008233
 >>> loss_box (detector): 0.000000
 >>> lr: 0.000025
speed: 0.040s / iter

##### DRL-RPN BATCH GRADIENT UPDATE - START ##### 

iter: 850 / 1000
lr-rl: 0.000004
Mean loss (tot, MA):      (-0.045880, -0.000397)
Mean reward (tot, MA):         (-6.038725, -2.091593)
Mean rew-done (tot, MA):       (-8.067645, -2.792845)
Mean traj-len (tot, MA):       (6.898822, 2.379712)
Mean frac-area (tot, MA):      (0.297957, 0.102421)
Mean gt >= 0.5 frac (tot, MA): (0.219837, 0.076028)
Mean gt-IoU-frac (tot, MA):    (0.137434, 0.047508)
Traj-len vs. # gt-instances:
['0.00', '2.00', '0.00', '0.00', '0.00', '0.00', '0.00', '12.00', '7.83', '6.89']
['0.00', '0.05', '0.00', '0.00', '0.00', '0.00', '0.00', '0.30', '2.09', '9.45']
Traj-len vs. betas:
['-2.000: 11.60', '0.350: 1.61']
['-2.000: 11.82', '0.350: 1.00']
TIMINGS:
runnn-drl-rpn: 0.3912
train-drl-rpn: 3.1505

##### DRL-RPN BATCH GRADIENT UPDATE - DONE ###### 

iter: 850 / 1000, total loss: 0.314284
 >>> loss_cls (detector): 0.148683
 >>> loss_box (detector): 0.083771
 >>> lr: 0.000025
speed: 0.040s / iter

##### DRL-RPN BATCH GRADIENT UPDATE - START ##### 

iter: 900 / 1000
lr-rl: 0.000004
Mean loss (tot, MA):      (-0.012747, -0.000122)
Mean reward (tot, MA):         (-6.567319, -2.424160)
Mean rew-done (tot, MA):       (-8.513885, -3.121603)
Mean traj-len (tot, MA):       (6.567775, 2.344157)
Mean frac-area (tot, MA):      (0.284358, 0.101205)
Mean gt >= 0.5 frac (tot, MA): (0.210875, 0.075596)
Mean gt-IoU-frac (tot, MA):    (0.131723, 0.047191)
Traj-len vs. # gt-instances:
['0.00', '2.00', '0.00', '0.00', '0.00', '0.00', '0.00', '12.00', '7.83', '6.55']
['0.00', '0.05', '0.00', '0.00', '0.00', '0.00', '0.00', '0.30', '2.09', '3.34']
Traj-len vs. betas:
['-2.000: 11.60', '0.350: 1.54']
['-2.000: 11.82', '0.350: 0.96']
TIMINGS:
runnn-drl-rpn: 0.3753
train-drl-rpn: 3.0480

##### DRL-RPN BATCH GRADIENT UPDATE - DONE ###### 

iter: 900 / 1000, total loss: 0.508579
 >>> loss_cls (detector): 0.149059
 >>> loss_box (detector): 0.277690
 >>> lr: 0.000025
speed: 0.040s / iter

##### DRL-RPN BATCH GRADIENT UPDATE - START ##### 

iter: 950 / 1000
lr-rl: 0.000004
Mean loss (tot, MA):      (-0.103547, -0.000991)
Mean reward (tot, MA):         (-6.132348, -2.322269)
Mean rew-done (tot, MA):       (-8.145784, -3.081963)
Mean traj-len (tot, MA):       (6.823155, 2.568345)
Mean frac-area (tot, MA):      (0.293267, 0.109911)
Mean gt >= 0.5 frac (tot, MA): (0.218252, 0.082401)
Mean gt-IoU-frac (tot, MA):    (0.136331, 0.051442)
Traj-len vs. # gt-instances:
['0.00', '2.00', '0.00', '0.00', '0.00', '0.00', '0.00', '12.00', '8.15', '6.80']
['0.00', '0.05', '0.00', '0.00', '0.00', '0.00', '0.00', '0.30', '2.33', '9.16']
Traj-len vs. betas:
['-2.000: 11.58', '0.350: 1.54']
['-2.000: 11.62', '0.350: 0.96']
TIMINGS:
runnn-drl-rpn: 0.3846
train-drl-rpn: 3.1189

##### DRL-RPN BATCH GRADIENT UPDATE - DONE ###### 

iter: 950 / 1000, total loss: 0.105112
 >>> loss_cls (detector): 0.023282
 >>> loss_box (detector): 0.000000
 >>> lr: 0.000025
speed: 0.039s / iter

##### DRL-RPN BATCH GRADIENT UPDATE - START ##### 

iter: 1000 / 1000
lr-rl: 0.000004
Mean loss (tot, MA):      (-0.034730, -0.000354)
Mean reward (tot, MA):         (-6.602571, -2.648646)
Mean rew-done (tot, MA):       (-8.534495, -3.399032)
Mean traj-len (tot, MA):       (6.521998, 2.524676)
Mean frac-area (tot, MA):      (0.280897, 0.108330)
Mean gt >= 0.5 frac (tot, MA): (0.209515, 0.081440)
Mean gt-IoU-frac (tot, MA):    (0.130859, 0.050835)
Traj-len vs. # gt-instances:
['0.00', '2.00', '0.00', '0.00', '0.00', '0.00', '0.00', '12.00', '8.15', '6.50']
['0.00', '0.05', '0.00', '0.00', '0.00', '0.00', '0.00', '0.30', '2.33', '3.16']
Traj-len vs. betas:
['-2.000: 11.58', '0.350: 1.46']
['-2.000: 11.62', '0.350: 0.85']
TIMINGS:
runnn-drl-rpn: 0.3703
train-drl-rpn: 3.0250

##### DRL-RPN BATCH GRADIENT UPDATE - DONE ###### 

iter: 1000 / 1000, total loss: 0.957085
 >>> loss_cls (detector): 0.264847
 >>> loss_box (detector): 0.610408
 >>> lr: 0.000025
speed: 0.039s / iter
Wrote snapshot to: /home/vador/Documents/project/AI/drl-rpn-tf/output-weights/drl-rpn-paris/output/vgg16_drl_rpn/paris_train/vgg16_drl_rpn_iter_1000.ckpt
done solving
531.76user 130.99system 12:20.63elapsed 89%CPU (0avgtext+0avgdata 9126296maxresident)k
5283592inputs+5799584outputs (956major+4814717minor)pagefaults 0swaps

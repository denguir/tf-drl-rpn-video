+ echo Logging output to experiments/logs/train/vgg16_paris_train_.txt.2019-04-05_19-23-13
Logging output to experiments/logs/train/vgg16_paris_train_.txt.2019-04-05_19-23-13
+ case ${DATASET} in
+ SAVE_PATH=/home/vador/Documents/project/AI/drl-rpn-tf/output-weights/drl-rpn-paris/
+ case ${USE_POST} in
+ WEIGHTS_PATH=/home/vador/Documents/project/AI/drl-rpn-tf/data/pre-trained/drl-rpn-voc2007-2012-trainval/vgg16_drl_rpn_iter_110000.ckpt
+ '[' '!' -f .index ']'
+ [[ ! -z '' ]]
+ CUDA_VISIBLE_DEVICES=0
+ time python ./tools/trainval_net.py --weight /home/vador/Documents/project/AI/drl-rpn-tf/data/pre-trained/drl-rpn-voc2007-2012-trainval/vgg16_drl_rpn_iter_110000.ckpt --save /home/vador/Documents/project/AI/drl-rpn-tf/output-weights/drl-rpn-paris/ --imdb paris_train --imdbval paris_val --iters 1000 --cfg experiments/cfgs/drl-rpn-vgg16.yml --net vgg16 --use_hist 1 --det_start 300 --use_post 0 --set ANCHOR_SCALES '[4,8,16]' ANCHOR_RATIOS '[0.5,1,2]' NBR_CLASSES 21 TRAIN.STEPSIZE '[700]' DRL_RPN_TRAIN.STEPSIZE 800
Called with args:
Namespace(cfg_file='experiments/cfgs/drl-rpn-vgg16.yml', det_start=300, imdb_name='paris_train', imdbval_name='paris_val', max_iters=1000, net='vgg16', save_path='/home/vador/Documents/project/AI/drl-rpn-tf/output-weights/drl-rpn-paris/', set_cfgs=['ANCHOR_SCALES', '[4,8,16]', 'ANCHOR_RATIOS', '[0.5,1,2]', 'NBR_CLASSES', '21', 'TRAIN.STEPSIZE', '[700]', 'DRL_RPN_TRAIN.STEPSIZE', '800'], tag=None, use_hist=1, use_post=0, weight='/home/vador/Documents/project/AI/drl-rpn-tf/data/pre-trained/drl-rpn-voc2007-2012-trainval/vgg16_drl_rpn_iter_110000.ckpt')
Using config:
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [4, 8, 16],
 'CLASS_NAMES': [],
 'COCO_TO_PASCAL': [0,
                    5,
                    2,
                    15,
                    9,
                    40,
                    6,
                    3,
                    16,
                    57,
                    20,
                    61,
                    17,
                    18,
                    4,
                    1,
                    59,
                    19,
                    58,
                    7,
                    63],
 'DATA_DIR': '/home/vador/Documents/project/AI/drl-rpn-tf/data',
 'DIMS_AUX': 39,
 'DIMS_BASE': 512,
 'DIMS_NONHIST': 530,
 'DIMS_TOT': 551,
 'DRL_RPN': {'H_FIXRECT': 0.25,
             'H_HIST': 3,
             'H_SCALE': 0.5,
             'MAX_ITER_TRAJ': 13,
             'MAX_ITER_TRAJ_FLT': 13.0,
             'TOPK_OBJNESS': 0,
             'USE_AGNO': False,
             'USE_HIST': True,
             'USE_POST': False,
             'W_FIXRECT': 0.25,
             'W_HIST': 3,
             'W_SCALE': 0.5},
 'DRL_RPN_TEST': {'BETA': 0.05,
                  'DO_VISUALIZE': False,
                  'NBR_FIX': 0,
                  'RANDOM_DONE': False,
                  'RANDOM_FIX': False},
 'DRL_RPN_TRAIN': {'BATCH_SIZE': 50,
                   'BETAS': [-1, 0.35],
                   'DET_START': -1,
                   'DISPLAY': 50,
                   'GAMMA': 0.2,
                   'IMG_START_IDX': -1,
                   'IOU_THRESH': 0.5,
                   'LEARNING_RATE': 2e-05,
                   'MA_WEIGHT': 0.0005,
                   'POST_BETAS': [0.05, 0.35],
                   'POST_LR': 0.001,
                   'POST_SS': [80000],
                   'STEPSIZE': 800,
                   'USE_BL': True,
                   'USE_FLIPPED': True,
                   'USE_POST': 0},
 'EXP_DIR': 'vgg16_drl_rpn',
 'MATLAB': 'matlab',
 'MEANS_BBOX': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),
 'NBR_ANCHORS': 9,
 'NBR_CLASSES': 21,
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/vador/Documents/project/AI/drl-rpn-tf',
 'RPN_CHANNELS': 512,
 'STDS_BBOX': array([0.1, 0.1, 0.2, 0.2, 0.1, 0.1, 0.2, 0.2, 0.1, 0.1, 0.2, 0.2, 0.1,
       0.1, 0.2, 0.2, 0.1, 0.1, 0.2, 0.2, 0.1, 0.1, 0.2, 0.2, 0.1, 0.1,
       0.2, 0.2, 0.1, 0.1, 0.2, 0.2, 0.1, 0.1, 0.2, 0.2, 0.1, 0.1, 0.2,
       0.2, 0.1, 0.1, 0.2, 0.2, 0.1, 0.1, 0.2, 0.2, 0.1, 0.1, 0.2, 0.2,
       0.1, 0.1, 0.2, 0.2, 0.1, 0.1, 0.2, 0.2, 0.1, 0.1, 0.2, 0.2, 0.1,
       0.1, 0.2, 0.2, 0.1, 0.1, 0.2, 0.2, 0.1, 0.1, 0.2, 0.2, 0.1, 0.1,
       0.2, 0.2, 0.1, 0.1, 0.2, 0.2]),
 'TEST': {'BBOX_REG': True,
          'HAS_RPN': True,
          'MAX_SIZE': 1000,
          'MODE': 'nms',
          'NMS': 0.3,
          'PROPOSAL_METHOD': 'gt',
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000,
          'RPN_TOP_N': 5000,
          'SCALES': [600],
          'SVM': False},
 'TRAIN': {'ASPECT_GROUPING': False,
           'BATCH_SIZE': 128,
           'BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'BBOX_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': True,
           'BBOX_REG': True,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'BIAS_DECAY': False,
           'DISPLAY': 50,
           'DOUBLE_BIAS': False,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'GAMMA': 0.1,
           'HAS_RPN': True,
           'IMS_PER_BATCH': 1,
           'LEARNING_RATE': 0.00025,
           'MAX_SIZE': 1000,
           'MOMENTUM': 0.9,
           'PROPOSAL_METHOD': 'gt',
           'RPN_BATCHSIZE': 128,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000,
           'SCALES': [600],
           'SNAPSHOT_ITERS': 5000,
           'SNAPSHOT_KEPT': 3,
           'SNAPSHOT_PREFIX': 'vgg16_drl_rpn',
           'STEPSIZE': [700],
           'SUMMARY_INTERVAL': 180,
           'TRUNCATED': False,
           'USE_ALL_GT': True,
           'USE_FLIPPED': True,
           'USE_GT': False,
           'WEIGHT_DECAY': 0.0001},
 'USE_GPU_NMS': True,
 'VIS_DIR': '/home/vador/Documents/project/AI/drl-rpn-tf/img-out'}
Loaded dataset `paris_train` for training
Set proposal method: gt
Appending horizontally-flipped training examples...
paris_train gt roidb loaded from /home/vador/Documents/project/AI/drl-rpn-tf/data/cache/paris_train_gt_roidb.pkl
done
Preparing training data...
done
2102 roidb entries
/home/vador/Documents/project/AI/drl-rpn-tf/output-weights/drl-rpn-paris/output/vgg16_drl_rpn/paris_train
Output will be saved to `/home/vador/Documents/project/AI/drl-rpn-tf/output-weights/drl-rpn-paris/output/vgg16_drl_rpn/paris_train`
Loaded dataset `paris_val` for training
Set proposal method: gt
Preparing training data...
paris_val gt roidb loaded from /home/vador/Documents/project/AI/drl-rpn-tf/data/cache/paris_val_gt_roidb.pkl
done
150 validation roidb entries
Filtered 0 roidb entries: 2102 -> 2102
Filtered 0 roidb entries: 150 -> 150
2019-04-05 19:23:17.016169: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-04-05 19:23:17.120411: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1009] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-04-05 19:23:17.121473: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x563417ac03d0 executing computations on platform CUDA. Devices:
2019-04-05 19:23:17.121499: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce RTX 2070, Compute Capability 7.5
2019-04-05 19:23:17.141096: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3392290000 Hz
2019-04-05 19:23:17.141442: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x563417deca10 executing computations on platform Host. Devices:
2019-04-05 19:23:17.141483: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-04-05 19:23:17.142205: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1551] Found device 0 with properties: 
name: GeForce RTX 2070 major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:01:00.0
totalMemory: 7.76GiB freeMemory: 7.23GiB
2019-04-05 19:23:17.142234: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1674] Adding visible gpu devices: 0
2019-04-05 19:23:17.142318: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-04-05 19:23:17.143977: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1082] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-04-05 19:23:17.144002: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1088]      0 
2019-04-05 19:23:17.144014: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1101] 0:   N 
2019-04-05 19:23:17.144670: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1222] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6360 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2070, pci bus id: 0000:01:00.0, compute capability: 7.5)
Solving...
WARNING: Logging before flag parsing goes to stderr.
W0405 19:23:17.368250 140337993451328 deprecation.py:323] From /home/vador/Documents/project/AI/drl-rpn-tf/tools/../lib/nets/network.py:222: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
W0405 19:23:17.372876 140337993451328 deprecation.py:323] From /home/vador/Documents/project/AI/drl-rpn-tf/tools/../lib/nets/network.py:231: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W0405 19:23:17.454235 140337993451328 deprecation.py:323] From /home/vador/Documents/project/AI/drl-rpn-tf/tools/../lib/nets/network.py:128: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
W0405 19:23:17.469768 140337993451328 deprecation.py:506] From /home/vador/Documents/project/AI/drl-rpn-tf/tools/../lib/nets/network.py:141: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.
Instructions for updating:
box_ind is deprecated, use box_indices instead
W0405 19:23:17.472787 140337993451328 deprecation.py:323] From /home/vador/anaconda3/envs/tf10/lib/python3.6/site-packages/tensorflow/contrib/layers/python/layers/layers.py:1624: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.flatten instead.
W0405 19:23:17.904685 140337993451328 deprecation.py:506] From /home/vador/anaconda3/envs/tf10/lib/python3.6/site-packages/tensorflow/python/training/slot_creator.py:187: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
Loading initial model weights from /home/vador/Documents/project/AI/drl-rpn-tf/data/pre-trained/drl-rpn-voc2007-2012-trainval/vgg16_drl_rpn_iter_110000.ckpt
Variables restored: vgg_16/conv1/conv1_1/biases:0
Variables restored: vgg_16/conv1/conv1_2/weights:0
Variables restored: vgg_16/conv1/conv1_2/biases:0
Variables restored: vgg_16/conv2/conv2_1/weights:0
Variables restored: vgg_16/conv2/conv2_1/biases:0
Variables restored: vgg_16/conv2/conv2_2/weights:0
Variables restored: vgg_16/conv2/conv2_2/biases:0
Variables restored: vgg_16/conv3/conv3_1/weights:0
Variables restored: vgg_16/conv3/conv3_1/biases:0
Variables restored: vgg_16/conv3/conv3_2/weights:0
Variables restored: vgg_16/conv3/conv3_2/biases:0
Variables restored: vgg_16/conv3/conv3_3/weights:0
Variables restored: vgg_16/conv3/conv3_3/biases:0
Variables restored: vgg_16/conv4/conv4_1/weights:0
Variables restored: vgg_16/conv4/conv4_1/biases:0
Variables restored: vgg_16/conv4/conv4_2/weights:0
Variables restored: vgg_16/conv4/conv4_2/biases:0
Variables restored: vgg_16/conv4/conv4_3/weights:0
Variables restored: vgg_16/conv4/conv4_3/biases:0
Variables restored: vgg_16/conv5/conv5_1/weights:0
Variables restored: vgg_16/conv5/conv5_1/biases:0
Variables restored: vgg_16/conv5/conv5_2/weights:0
Variables restored: vgg_16/conv5/conv5_2/biases:0
Variables restored: vgg_16/conv5/conv5_3/weights:0
Variables restored: vgg_16/conv5/conv5_3/biases:0
Variables restored: vgg_16/rpn_conv/3x3/weights:0
Variables restored: vgg_16/rpn_conv/3x3/biases:0
Variables restored: vgg_16/rpn_cls_score/weights:0
Variables restored: vgg_16/rpn_cls_score/biases:0
Variables restored: vgg_16/rpn_bbox_pred/weights:0
Variables restored: vgg_16/rpn_bbox_pred/biases:0
Variables restored: vgg_16/fc6/biases:0
Variables restored: vgg_16/fc7/biases:0
Variables restored: vgg_16/cls_score/weights:0
Variables restored: vgg_16/cls_score/biases:0
Variables restored: vgg_16/bbox_pred/weights:0
Variables restored: vgg_16/bbox_pred/biases:0
Variables restored: post_hist/vgg_16/fc6/weights:0
Variables restored: post_hist/vgg_16/fc6/biases:0
Variables restored: post_hist/vgg_16/fc7/weights:0
Variables restored: post_hist/vgg_16/fc7/biases:0
Variables restored: post_hist/hist_tanh_cls/weights:0
Variables restored: post_hist/hist_tanh_cls/biases:0
Variables restored: post_hist/cls_score_hist/weights:0
Variables restored: post_hist/cls_score_hist/biases:0
Variables restored: Variable:0
Variables restored: vgg_16/fc6/weights/Momentum:0
Variables restored: vgg_16/fc6/biases/Momentum:0
Variables restored: vgg_16/fc7/weights/Momentum:0
Variables restored: vgg_16/fc7/biases/Momentum:0
Variables restored: vgg_16/cls_score/weights/Momentum:0
Variables restored: vgg_16/cls_score/biases/Momentum:0
Variables restored: vgg_16/bbox_pred/weights/Momentum:0
Variables restored: vgg_16/bbox_pred/biases/Momentum:0
Variables restored: post_hist/vgg_16/fc6/weights/Momentum:0
Variables restored: post_hist/vgg_16/fc7/weights/Momentum:0
Variables restored: post_hist/hist_tanh_cls/weights/Momentum:0
Variables restored: post_hist/cls_score_hist/weights/Momentum:0
Variables restored: Variable_1:0
Variables restored: post_hist/vgg_16/fc6/weights/Momentum_1:0
Variables restored: post_hist/vgg_16/fc6/biases/Momentum:0
Variables restored: post_hist/vgg_16/fc7/weights/Momentum_1:0
Variables restored: post_hist/vgg_16/fc7/biases/Momentum:0
Variables restored: post_hist/hist_tanh_cls/weights/Momentum_1:0
Variables restored: post_hist/hist_tanh_cls/biases/Momentum:0
Variables restored: post_hist/cls_score_hist/weights/Momentum_1:0
Variables restored: post_hist/cls_score_hist/biases/Momentum:0
Variables restored: xr_weights_base:0
Variables restored: xr_weights_aux:0
Variables restored: xh_weights_base:0
Variables restored: xh_weights_aux:0
Variables restored: xz_weights_base:0
Variables restored: xz_weights_aux:0
Variables restored: hr_weights:0
Variables restored: hh_weights:0
Variables restored: hz_weights:0
Variables restored: h_relu_weights:0
Variables restored: r_bias:0
Variables restored: h_bias:0
Variables restored: z_bias:0
Variables restored: relu_bias:0
Variables restored: additional_weights:0
Variables restored: additional_bias:0
Variables restored: done_weights:0
W0405 19:23:22.915491 140337993451328 deprecation.py:323] From /home/vador/anaconda3/envs/tf10/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
Loaded.
Fix VGG16 layers..
OBS: NOT REVERSING RGB CHANNELS -- set do_reverse=True if reversing is desired!
W0405 19:23:47.736482 140337993451328 deprecation.py:506] From /home/vador/anaconda3/envs/tf10/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
Fixed.
2019-04-05 19:23:55.559544: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-04-05 19:24:00.711223: W tensorflow/core/common_runtime/bfc_allocator.cc:230] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.09GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-04-05 19:24:00.711268: W tensorflow/core/common_runtime/bfc_allocator.cc:230] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.09GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-04-05 19:24:01.654884: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:697] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-04-05 19:24:01.655929: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:697] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-04-05 19:24:01.700296: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0

##### DRL-RPN BATCH GRADIENT UPDATE - START ##### 

iter: 50 / 1000
lr-rl: 0.000020
2019-04-05 19:24:33.569129: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:697] Iteration = 0, topological sort failed with message: The graph couldn't be sorted in topological order.
2019-04-05 19:24:33.574071: E tensorflow/core/grappler/optimizers/dependency_optimizer.cc:697] Iteration = 1, topological sort failed with message: The graph couldn't be sorted in topological order.
Mean loss (tot, MA):      (-0.117559, -0.000059)
Mean reward (tot, MA):         (3.048263, 0.075333)
Mean rew-done (tot, MA):       (-0.500000, -0.012348)
Mean traj-len (tot, MA):       (12.000000, 0.296354)
Mean frac-area (tot, MA):      (0.518611, 0.012808)
Mean gt >= 0.5 frac (tot, MA): (0.388984, 0.009609)
Mean gt-IoU-frac (tot, MA):    (0.246183, 0.006082)
Traj-len vs. # gt-instances:
['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '12.00', '12.00']
['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.30', '8.53']
Traj-len vs. betas:
['-1.000: 12.00', '0.350: 0.00']
['-1.000: 8.62', '0.350: 0.00']
TIMINGS:
runnn-drl-rpn: 0.7548
train-drl-rpn: 5.2289

##### DRL-RPN BATCH GRADIENT UPDATE - DONE ###### 


##### DRL-RPN BATCH GRADIENT UPDATE - START ##### 

iter: 100 / 1000
lr-rl: 0.000020
Mean loss (tot, MA):      (1.716238, 0.001716)
Mean reward (tot, MA):         (-5.331825, -0.265062)
Mean rew-done (tot, MA):       (-8.060000, -0.397668)
Mean traj-len (tot, MA):       (7.860001, 0.380943)
Mean frac-area (tot, MA):      (0.363600, 0.017645)
Mean gt >= 0.5 frac (tot, MA): (0.293758, 0.014273)
Mean gt-IoU-frac (tot, MA):    (0.186020, 0.009039)
Traj-len vs. # gt-instances:
['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '8.00', '7.86']
['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.39', '5.17']
Traj-len vs. betas:
['-1.000: 12.00', '0.350: 3.72']
['-1.000: 8.62', '0.350: 2.74']
TIMINGS:
runnn-drl-rpn: 0.5086
train-drl-rpn: 3.6606

##### DRL-RPN BATCH GRADIENT UPDATE - DONE ###### 


##### DRL-RPN BATCH GRADIENT UPDATE - START ##### 

iter: 150 / 1000
lr-rl: 0.000020
Mean loss (tot, MA):      (0.205220, 0.000307)
Mean reward (tot, MA):         (-3.429904, -0.249303)
Mean rew-done (tot, MA):       (-6.146665, -0.445175)
Mean traj-len (tot, MA):       (8.966672, 0.647602)
Mean frac-area (tot, MA):      (0.403930, 0.029174)
Mean gt >= 0.5 frac (tot, MA): (0.291458, 0.021004)
Mean gt-IoU-frac (tot, MA):    (0.184568, 0.013301)
Traj-len vs. # gt-instances:
['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '8.00', '8.98']
['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.39', '9.43']
Traj-len vs. betas:
['-1.000: 11.59', '0.350: 3.72']
['-1.000: 10.40', '0.350: 2.74']
TIMINGS:
runnn-drl-rpn: 0.5299
train-drl-rpn: 3.8730

##### DRL-RPN BATCH GRADIENT UPDATE - DONE ###### 


##### DRL-RPN BATCH GRADIENT UPDATE - START ##### 

iter: 200 / 1000
lr-rl: 0.000020
Mean loss (tot, MA):      (0.824288, 0.001648)
Mean reward (tot, MA):         (-5.892831, -0.571327)
Mean rew-done (tot, MA):       (-8.244997, -0.793461)
Mean traj-len (tot, MA):       (7.455002, 0.703776)
Mean frac-area (tot, MA):      (0.343284, 0.032441)
Mean gt >= 0.5 frac (tot, MA): (0.252504, 0.023836)
Mean gt-IoU-frac (tot, MA):    (0.160436, 0.015148)
Traj-len vs. # gt-instances:
['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '4.80', '7.52']
['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.56', '4.98']
Traj-len vs. betas:
['-1.000: 11.59', '0.350: 3.32']
['-1.000: 10.40', '0.350: 2.95']
TIMINGS:
runnn-drl-rpn: 0.4513
train-drl-rpn: 3.3633

##### DRL-RPN BATCH GRADIENT UPDATE - DONE ###### 


##### DRL-RPN BATCH GRADIENT UPDATE - START ##### 

iter: 250 / 1000
lr-rl: 0.000020
Mean loss (tot, MA):      (0.153857, 0.000383)
Mean reward (tot, MA):         (-4.364966, -0.514198)
Mean rew-done (tot, MA):       (-6.915998, -0.813401)
Mean traj-len (tot, MA):       (8.292001, 0.973823)
Mean frac-area (tot, MA):      (0.375524, 0.044098)
Mean gt >= 0.5 frac (tot, MA): (0.271319, 0.031799)
Mean gt-IoU-frac (tot, MA):    (0.172849, 0.020263)
Traj-len vs. # gt-instances:
['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '4.80', '8.36']
['0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.56', '9.71']
Traj-len vs. betas:
['-1.000: 11.61', '0.350: 3.32']
['-1.000: 11.24', '0.350: 2.95']
TIMINGS:
runnn-drl-rpn: 0.4798
train-drl-rpn: 3.5761

##### DRL-RPN BATCH GRADIENT UPDATE - DONE ###### 


##### DRL-RPN BATCH GRADIENT UPDATE - START ##### 

iter: 300 / 1000
lr-rl: 0.000020
Mean loss (tot, MA):      (0.556567, 0.001668)
Mean reward (tot, MA):         (-5.954363, -0.844782)
Mean rew-done (tot, MA):       (-8.206664, -1.155287)
Mean traj-len (tot, MA):       (7.276667, 1.004076)
Mean frac-area (tot, MA):      (0.333526, 0.046060)
Mean gt >= 0.5 frac (tot, MA): (0.240116, 0.033087)
Mean gt-IoU-frac (tot, MA):    (0.152731, 0.021048)
Traj-len vs. # gt-instances:
['0.00', '3.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '4.80', '7.33']
['0.00', '0.08', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.56', '4.32']
Traj-len vs. betas:
['-1.000: 11.61', '0.350: 2.95']
['-1.000: 11.24', '0.350: 2.37']
TIMINGS:
runnn-drl-rpn: 0.4291
train-drl-rpn: 3.2555

##### DRL-RPN BATCH GRADIENT UPDATE - DONE ###### 


##### DRL-RPN BATCH GRADIENT UPDATE - START ##### 

iter: 350 / 1000
lr-rl: 0.000020
Mean loss (tot, MA):      (0.282816, 0.000987)
Mean reward (tot, MA):         (-4.937249, -0.794997)
Mean rew-done (tot, MA):       (-7.347139, -1.180701)
Mean traj-len (tot, MA):       (7.805714, 1.250560)
Mean frac-area (tot, MA):      (0.353844, 0.056676)
Mean gt >= 0.5 frac (tot, MA): (0.258313, 0.041344)
Mean gt-IoU-frac (tot, MA):    (0.163787, 0.026210)
Traj-len vs. # gt-instances:
['0.00', '3.00', '0.00', '0.00', '0.00', '0.00', '0.00', '12.00', '6.00', '7.84']
['0.00', '0.08', '0.00', '0.00', '0.00', '0.00', '0.00', '0.30', '0.85', '9.14']
Traj-len vs. betas:
['-1.000: 11.45', '0.350: 2.95']
['-1.000: 11.22', '0.350: 2.37']
TIMINGS:
runnn-drl-rpn: 0.4515
train-drl-rpn: 3.4035

##### DRL-RPN BATCH GRADIENT UPDATE - DONE ###### 

iter: 350 / 1000, total loss: 0.464324
 >>> loss_cls (detector): 0.229082
 >>> loss_box (detector): 0.153400
 >>> lr: 0.000250
speed: 0.041s / iter

##### DRL-RPN BATCH GRADIENT UPDATE - START ##### 

iter: 400 / 1000
lr-rl: 0.000020
Mean loss (tot, MA):      (0.664903, 0.002656)
Mean reward (tot, MA):         (-6.110636, -1.129111)
Mean rew-done (tot, MA):       (-8.366242, -1.534359)
Mean traj-len (tot, MA):       (7.102501, 1.273510)
Mean frac-area (tot, MA):      (0.324632, 0.058243)
Mean gt >= 0.5 frac (tot, MA): (0.241986, 0.043479)
Mean gt-IoU-frac (tot, MA):    (0.153287, 0.027535)
Traj-len vs. # gt-instances:
['0.00', '3.00', '0.00', '0.00', '0.00', '0.00', '0.00', '12.00', '6.00', '7.12']
['0.00', '0.08', '0.00', '0.00', '0.00', '0.00', '0.00', '0.30', '0.85', '4.14']
Traj-len vs. betas:
['-1.000: 11.45', '0.350: 2.75']
['-1.000: 11.22', '0.350: 2.23']
TIMINGS:
runnn-drl-rpn: 0.4170
train-drl-rpn: 3.1809

##### DRL-RPN BATCH GRADIENT UPDATE - DONE ###### 

iter: 400 / 1000, total loss: 0.498803
 >>> loss_cls (detector): 0.194799
 >>> loss_box (detector): 0.222163
 >>> lr: 0.000250
speed: 0.040s / iter

##### DRL-RPN BATCH GRADIENT UPDATE - START ##### 

iter: 450 / 1000
lr-rl: 0.000020
Mean loss (tot, MA):      (0.316879, 0.001421)
Mean reward (tot, MA):         (-5.248197, -1.060304)
Mean rew-done (tot, MA):       (-7.652218, -1.544235)
Mean traj-len (tot, MA):       (7.593336, 1.526625)
Mean frac-area (tot, MA):      (0.345682, 0.069504)
Mean gt >= 0.5 frac (tot, MA): (0.257263, 0.051783)
Mean gt-IoU-frac (tot, MA):    (0.162690, 0.032733)
Traj-len vs. # gt-instances:
['0.00', '3.00', '0.00', '0.00', '0.00', '0.00', '0.00', '12.00', '6.86', '7.61']
['0.00', '0.08', '0.00', '0.00', '0.00', '0.00', '0.00', '0.30', '1.12', '9.47']
Traj-len vs. betas:
['-1.000: 11.46', '0.350: 2.75']
['-1.000: 11.53', '0.350: 2.23']
TIMINGS:
runnn-drl-rpn: 0.4395
train-drl-rpn: 3.3209

##### DRL-RPN BATCH GRADIENT UPDATE - DONE ###### 

iter: 450 / 1000, total loss: 0.244251
 >>> loss_cls (detector): 0.162412
 >>> loss_box (detector): 0.000000
 >>> lr: 0.000250
speed: 0.039s / iter

##### DRL-RPN BATCH GRADIENT UPDATE - START ##### 

iter: 500 / 1000
lr-rl: 0.000020
Mean loss (tot, MA):      (0.617162, 0.003080)
Mean reward (tot, MA):         (-6.169680, -1.391283)
Mean rew-done (tot, MA):       (-8.444996, -1.890869)
Mean traj-len (tot, MA):       (7.028003, 1.536763)
Mean frac-area (tot, MA):      (0.321777, 0.070417)
Mean gt >= 0.5 frac (tot, MA): (0.243082, 0.053356)
Mean gt-IoU-frac (tot, MA):    (0.153752, 0.033737)
Traj-len vs. # gt-instances:
['0.00', '3.00', '0.00', '0.00', '0.00', '0.00', '0.00', '12.00', '6.86', '7.03']
['0.00', '0.08', '0.00', '0.00', '0.00', '0.00', '0.00', '0.30', '1.12', '3.96']
Traj-len vs. betas:
['-1.000: 11.46', '0.350: 2.59']
['-1.000: 11.53', '0.350: 1.92']
TIMINGS:
runnn-drl-rpn: 0.4116
train-drl-rpn: 3.1461

##### DRL-RPN BATCH GRADIENT UPDATE - DONE ###### 

iter: 500 / 1000, total loss: 0.279701
 >>> loss_cls (detector): 0.107433
 >>> loss_box (detector): 0.090432
 >>> lr: 0.000250
speed: 0.039s / iter

##### DRL-RPN BATCH GRADIENT UPDATE - START ##### 

iter: 550 / 1000
lr-rl: 0.000020
Mean loss (tot, MA):      (0.379373, 0.002080)
Mean reward (tot, MA):         (-5.378616, -1.294369)
Mean rew-done (tot, MA):       (-7.799084, -1.877232)
Mean traj-len (tot, MA):       (7.423639, 1.779873)
Mean frac-area (tot, MA):      (0.337759, 0.080968)
Mean gt >= 0.5 frac (tot, MA): (0.259023, 0.062373)
Mean gt-IoU-frac (tot, MA):    (0.163593, 0.039374)
Traj-len vs. # gt-instances:
['0.00', '3.00', '0.00', '0.00', '0.00', '0.00', '0.00', '12.00', '7.40', '7.42']
['0.00', '0.08', '0.00', '0.00', '0.00', '0.00', '0.00', '0.30', '1.67', '9.32']
Traj-len vs. betas:
['-1.000: 11.45', '0.350: 2.59']
['-1.000: 11.44', '0.350: 1.92']
TIMINGS:
runnn-drl-rpn: 0.4288
train-drl-rpn: 3.2591

##### DRL-RPN BATCH GRADIENT UPDATE - DONE ###### 

iter: 550 / 1000, total loss: 0.344022
 >>> loss_cls (detector): 0.235219
 >>> loss_box (detector): 0.026968
 >>> lr: 0.000250
speed: 0.039s / iter

##### DRL-RPN BATCH GRADIENT UPDATE - START ##### 

iter: 600 / 1000
lr-rl: 0.000020
Mean loss (tot, MA):      (0.420599, 0.002516)
Mean reward (tot, MA):         (-6.181979, -1.633301)
Mean rew-done (tot, MA):       (-8.455829, -2.218084)
Mean traj-len (tot, MA):       (6.923335, 1.770971)
Mean frac-area (tot, MA):      (0.316165, 0.080910)
Mean gt >= 0.5 frac (tot, MA): (0.243040, 0.062492)
Mean gt-IoU-frac (tot, MA):    (0.153525, 0.039458)
Traj-len vs. # gt-instances:
['0.00', '3.00', '0.00', '0.00', '0.00', '0.00', '0.00', '12.00', '7.40', '6.91']
['0.00', '0.08', '0.00', '0.00', '0.00', '0.00', '0.00', '0.30', '1.67', '3.63']
Traj-len vs. betas:
['-1.000: 11.45', '0.350: 2.40']
['-1.000: 11.44', '0.350: 1.54']
TIMINGS:
runnn-drl-rpn: 0.4040
train-drl-rpn: 3.1077

##### DRL-RPN BATCH GRADIENT UPDATE - DONE ###### 

iter: 600 / 1000, total loss: 0.867756
 >>> loss_cls (detector): 0.348841
 >>> loss_box (detector): 0.437082
 >>> lr: 0.000250
speed: 0.039s / iter

##### DRL-RPN BATCH GRADIENT UPDATE - START ##### 

iter: 650 / 1000
lr-rl: 0.000020
Mean loss (tot, MA):      (0.236165, 0.001526)
Mean reward (tot, MA):         (-5.536667, -1.538517)
Mean rew-done (tot, MA):       (-7.912305, -2.197736)
Mean traj-len (tot, MA):       (7.276925, 2.011677)
Mean frac-area (tot, MA):      (0.330583, 0.091346)
Mean gt >= 0.5 frac (tot, MA): (0.252990, 0.070147)
Mean gt-IoU-frac (tot, MA):    (0.159520, 0.044200)
Traj-len vs. # gt-instances:
['0.00', '3.00', '0.00', '0.00', '0.00', '0.00', '0.00', '12.00', '7.40', '7.27']
['0.00', '0.08', '0.00', '0.00', '0.00', '0.00', '0.00', '0.30', '1.67', '9.23']
Traj-len vs. betas:
['-1.000: 11.46', '0.350: 2.40']
['-1.000: 11.43', '0.350: 1.54']
TIMINGS:
runnn-drl-rpn: 0.4197
train-drl-rpn: 3.2146

##### DRL-RPN BATCH GRADIENT UPDATE - DONE ###### 

iter: 650 / 1000, total loss: 0.307751
 >>> loss_cls (detector): 0.144160
 >>> loss_box (detector): 0.081759
 >>> lr: 0.000250
speed: 0.039s / iter

##### DRL-RPN BATCH GRADIENT UPDATE - START ##### 

iter: 700 / 1000
lr-rl: 0.000020
Mean loss (tot, MA):      (0.288669, 0.002011)
Mean reward (tot, MA):         (-6.207214, -1.869204)
Mean rew-done (tot, MA):       (-8.461428, -2.528819)
Mean traj-len (tot, MA):       (6.837144, 1.989670)
Mean frac-area (tot, MA):      (0.311493, 0.090656)
Mean gt >= 0.5 frac (tot, MA): (0.239922, 0.070142)
Mean gt-IoU-frac (tot, MA):    (0.151289, 0.044201)
Traj-len vs. # gt-instances:
['0.00', '3.00', '0.00', '0.00', '0.00', '0.00', '0.00', '12.00', '7.40', '6.83']
['0.00', '0.08', '0.00', '0.00', '0.00', '0.00', '0.00', '0.30', '1.67', '3.43']
Traj-len vs. betas:
['-1.000: 11.46', '0.350: 2.21']
['-1.000: 11.43', '0.350: 1.27']
TIMINGS:
runnn-drl-rpn: 0.3980
train-drl-rpn: 3.0796

##### DRL-RPN BATCH GRADIENT UPDATE - DONE ###### 

iter: 700 / 1000, total loss: 0.991459
 >>> loss_cls (detector): 0.339440
 >>> loss_box (detector): 0.570189
 >>> lr: 0.000025
speed: 0.039s / iter

##### DRL-RPN BATCH GRADIENT UPDATE - START ##### 

iter: 750 / 1000
lr-rl: 0.000020
Mean loss (tot, MA):      (0.177377, 0.001319)
Mean reward (tot, MA):         (-5.597258, -1.750317)
Mean rew-done (tot, MA):       (-7.945998, -2.484379)
Mean traj-len (tot, MA):       (7.165333, 2.230976)
Mean frac-area (tot, MA):      (0.323186, 0.100443)
Mean gt >= 0.5 frac (tot, MA): (0.251294, 0.078549)
Mean gt-IoU-frac (tot, MA):    (0.158145, 0.049387)
Traj-len vs. # gt-instances:
['0.00', '3.00', '0.00', '0.00', '0.00', '0.00', '0.00', '12.00', '7.40', '7.16']
['0.00', '0.08', '0.00', '0.00', '0.00', '0.00', '0.00', '0.30', '1.67', '9.44']
Traj-len vs. betas:
['-1.000: 11.50', '0.350: 2.21']
['-1.000: 11.70', '0.350: 1.27']
TIMINGS:
runnn-drl-rpn: 0.4121
train-drl-rpn: 3.2000

##### DRL-RPN BATCH GRADIENT UPDATE - DONE ###### 

iter: 750 / 1000, total loss: 0.081983
 >>> loss_cls (detector): 0.000152
 >>> loss_box (detector): 0.000000
 >>> lr: 0.000025
speed: 0.039s / iter

##### DRL-RPN BATCH GRADIENT UPDATE - START ##### 

iter: 800 / 1000
lr-rl: 0.000004
Mean loss (tot, MA):      (0.200160, 0.001590)
Mean reward (tot, MA):         (-6.203074, -2.084595)
Mean rew-done (tot, MA):       (-8.444374, -2.816098)
Mean traj-len (tot, MA):       (6.781250, 2.201066)
Mean frac-area (tot, MA):      (0.306437, 0.099325)
Mean gt >= 0.5 frac (tot, MA): (0.239469, 0.078145)
Mean gt-IoU-frac (tot, MA):    (0.150748, 0.049151)
Traj-len vs. # gt-instances:
['0.00', '3.00', '0.00', '0.00', '0.00', '0.00', '0.00', '12.00', '6.82', '6.78']
['0.00', '0.08', '0.00', '0.00', '0.00', '0.00', '0.00', '0.30', '1.65', '3.45']
Traj-len vs. betas:
['-1.000: 11.50', '0.350: 2.06']
['-1.000: 11.70', '0.350: 1.08']
TIMINGS:
runnn-drl-rpn: 0.3932
train-drl-rpn: 3.0819

##### DRL-RPN BATCH GRADIENT UPDATE - DONE ###### 

iter: 800 / 1000, total loss: 0.217405
 >>> loss_cls (detector): 0.095008
 >>> loss_box (detector): 0.040566
 >>> lr: 0.000025
speed: 0.039s / iter

##### DRL-RPN BATCH GRADIENT UPDATE - START ##### 

iter: 850 / 1000
lr-rl: 0.000004
Mean loss (tot, MA):      (0.047592, 0.000392)
Mean reward (tot, MA):         (-5.705574, -1.977388)
Mean rew-done (tot, MA):       (-8.024706, -2.778885)
Mean traj-len (tot, MA):       (7.062353, 2.432250)
Mean frac-area (tot, MA):      (0.316982, 0.108871)
Mean gt >= 0.5 frac (tot, MA): (0.249008, 0.086133)
Mean gt-IoU-frac (tot, MA):    (0.156647, 0.054136)
Traj-len vs. # gt-instances:
['0.00', '3.00', '0.00', '0.00', '0.00', '0.00', '0.00', '12.00', '7.25', '7.06']
['0.00', '0.08', '0.00', '0.00', '0.00', '0.00', '0.00', '0.30', '1.91', '9.28']
Traj-len vs. betas:
['-1.000: 11.50', '0.350: 2.06']
['-1.000: 11.67', '0.350: 1.08']
TIMINGS:
runnn-drl-rpn: 0.4049
train-drl-rpn: 3.1593

##### DRL-RPN BATCH GRADIENT UPDATE - DONE ###### 

iter: 850 / 1000, total loss: 0.165302
 >>> loss_cls (detector): 0.055996
 >>> loss_box (detector): 0.027475
 >>> lr: 0.000025
speed: 0.039s / iter

##### DRL-RPN BATCH GRADIENT UPDATE - START ##### 

iter: 900 / 1000
lr-rl: 0.000004
Mean loss (tot, MA):      (0.021042, 0.000177)
Mean reward (tot, MA):         (-6.256618, -2.314520)
Mean rew-done (tot, MA):       (-8.473333, -3.107988)
Mean traj-len (tot, MA):       (6.725556, 2.396878)
Mean frac-area (tot, MA):      (0.302477, 0.107563)
Mean gt >= 0.5 frac (tot, MA): (0.238208, 0.085356)
Mean gt-IoU-frac (tot, MA):    (0.149778, 0.053616)
Traj-len vs. # gt-instances:
['0.00', '3.00', '0.00', '0.00', '0.00', '0.00', '0.00', '12.00', '7.25', '6.72']
['0.00', '0.08', '0.00', '0.00', '0.00', '0.00', '0.00', '0.30', '1.91', '3.33']
Traj-len vs. betas:
['-1.000: 11.50', '0.350: 1.95']
['-1.000: 11.67', '0.350: 1.02']
TIMINGS:
runnn-drl-rpn: 0.3886
train-drl-rpn: 3.0574

##### DRL-RPN BATCH GRADIENT UPDATE - DONE ###### 

iter: 900 / 1000, total loss: 0.493735
 >>> loss_cls (detector): 0.127555
 >>> loss_box (detector): 0.284349
 >>> lr: 0.000025
speed: 0.039s / iter

##### DRL-RPN BATCH GRADIENT UPDATE - START ##### 

iter: 950 / 1000
lr-rl: 0.000004
Mean loss (tot, MA):      (-0.092800, -0.000894)
Mean reward (tot, MA):         (-5.825708, -2.209608)
Mean rew-done (tot, MA):       (-8.107894, -3.068923)
Mean traj-len (tot, MA):       (6.981054, 2.623753)
Mean frac-area (tot, MA):      (0.312625, 0.117142)
Mean gt >= 0.5 frac (tot, MA): (0.245331, 0.092470)
Mean gt-IoU-frac (tot, MA):    (0.154215, 0.058070)
Traj-len vs. # gt-instances:
['0.00', '3.00', '0.00', '0.00', '0.00', '0.00', '0.00', '12.00', '7.62', '6.97']
['0.00', '0.08', '0.00', '0.00', '0.00', '0.00', '0.00', '0.30', '2.16', '9.29']
Traj-len vs. betas:
['-1.000: 11.51', '0.350: 1.95']
['-1.000: 11.71', '0.350: 1.02']
TIMINGS:
runnn-drl-rpn: 0.4005
train-drl-rpn: 3.1408

##### DRL-RPN BATCH GRADIENT UPDATE - DONE ###### 

iter: 950 / 1000, total loss: 0.117197
 >>> loss_cls (detector): 0.035367
 >>> loss_box (detector): 0.000000
 >>> lr: 0.000025
speed: 0.039s / iter

##### DRL-RPN BATCH GRADIENT UPDATE - START ##### 

iter: 1000 / 1000
lr-rl: 0.000004
Mean loss (tot, MA):      (-0.060278, -0.000615)
Mean reward (tot, MA):         (-6.308332, -2.537328)
Mean rew-done (tot, MA):       (-8.498502, -3.386314)
Mean traj-len (tot, MA):       (6.679001, 2.582172)
Mean frac-area (tot, MA):      (0.299572, 0.115523)
Mean gt >= 0.5 frac (tot, MA): (0.235259, 0.091268)
Mean gt-IoU-frac (tot, MA):    (0.147889, 0.057319)
Traj-len vs. # gt-instances:
['0.00', '3.00', '0.00', '0.00', '0.00', '0.00', '0.00', '12.00', '7.62', '6.66']
['0.00', '0.08', '0.00', '0.00', '0.00', '0.00', '0.00', '0.30', '2.16', '3.30']
Traj-len vs. betas:
['-1.000: 11.51', '0.350: 1.85']
['-1.000: 11.71', '0.350: 0.97']
TIMINGS:
runnn-drl-rpn: 0.3857
train-drl-rpn: 3.0484

##### DRL-RPN BATCH GRADIENT UPDATE - DONE ###### 

iter: 1000 / 1000, total loss: 0.665215
 >>> loss_cls (detector): 0.134204
 >>> loss_box (detector): 0.449181
 >>> lr: 0.000025
speed: 0.039s / iter
Wrote snapshot to: /home/vador/Documents/project/AI/drl-rpn-tf/output-weights/drl-rpn-paris/output/vgg16_drl_rpn/paris_train/vgg16_drl_rpn_iter_1000.ckpt
done solving
593.51user 150.15system 13:20.33elapsed 92%CPU (0avgtext+0avgdata 9082832maxresident)k
5222424inputs+5799584outputs (956major+4762564minor)pagefaults 0swaps
